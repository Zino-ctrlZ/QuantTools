{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "os.environ['STREAM_LOG_LEVEL'] = 'ERROR'\n",
    "os.environ['FILE_LOG_LEVEL'] = 'DEBUG'\n",
    "os.environ['PROPAGATE_TO_ROOT_LOGGER'] = 'False'\n",
    "os.environ['PROPAGATE_TO_ROOT_LOGGER'], os.environ['STREAM_LOG_LEVEL']\n",
    "from trade.assets.Stock import Stock\n",
    "from trade.assets.Option import Option\n",
    "from trade.assets.OptionStructure import OptionStructure\n",
    "from trade.helpers.Context import Context, clear_context\n",
    "from trade.helpers.helper import (change_to_last_busday, \n",
    "                                  is_USholiday, \n",
    "                                  is_busday, \n",
    "                                  setup_logger, \n",
    "                                  generate_option_tick, \n",
    "                                  get_option_specifics_from_key,\n",
    "                                  identify_length,\n",
    "                                  extract_numeric_value)\n",
    "from scipy.stats import percentileofscore\n",
    "from EventDriven.riskmanager import RiskManager\n",
    "from dbase.DataAPI.ThetaData import (list_contracts, retrieve_openInterest, retrieve_eod_ohlc, retrieve_quote)\n",
    "from pandas.tseries.offsets import BDay\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import numpy as np\n",
    "import time\n",
    "chain_cache = {}\n",
    "close_cache = {}\n",
    "oi_cache = {}\n",
    "spot_cache = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['AAPL20250620000235C'],\n",
       " 'S': ['AAPL20250620000260C'],\n",
       " 'trade_id': '&L:AAPL20250620000235C&S:AAPL20250620000260C',\n",
       " 'close': 4.925000000000001}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EventDriven.riskmanager import RiskManager, spot_cache, oi_cache, close_cache, chain_cache\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pandas as pd\n",
    "\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.15},\n",
    "                {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.15} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }\n",
    "tick = 'AAPL'\n",
    "date = '2024-07-24'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'C'\n",
    "\n",
    "rm = RiskManager(None, None, 1000000)\n",
    "rm.OrderPicker.get_order(tick, date, 'C', 5, order_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLE ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = 'BAC'\n",
    "date = '2023-07-24'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'C'\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.15},\n",
    "                # {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.15} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTIPROCESSING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from abc import ABC, abstractmethod\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from pathos.multiprocessing import cpu_count\n",
    "from pathos.pools import _ProcessPool\n",
    "from threading import Thread\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "shutdown_event = False\n",
    "\n",
    "def runProcesses(func, OrderedInputs: List[List], run_type: str = 'map') -> List:\n",
    "    global shutdown_event\n",
    "    try:\n",
    "\n",
    "        pool = Pool(20)\n",
    "        pool.restart()\n",
    "        if run_type == 'map':\n",
    "            results = pool.map(func, *OrderedInputs)\n",
    "        elif run_type == 'amap':\n",
    "            results = pool.amap(func, *OrderedInputs)\n",
    "        elif run_type == 'uimap':\n",
    "            results = pool.uimap(func, *OrderedInputs)\n",
    "        elif run_type == 'imap':\n",
    "            results = pool.imap(func, *OrderedInputs)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'Run type {run_type} not recognized')\n",
    "\n",
    "    except KeyboardInterrupt as e:\n",
    "\n",
    "        shutdown_event = True\n",
    "        shutdown(pool)\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error occured: ', e)\n",
    "        shutdown(pool)\n",
    "\n",
    "\n",
    "    finally:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def shutdown(pool):\n",
    "    global shutdown_event\n",
    "    shutdown_event\n",
    "    shutdown_event = True\n",
    "    pool.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELEVANT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_closePrice(id, date):\n",
    "    global close_cache, spot_cache\n",
    "    cache_key = f\"{id}_{date}\"\n",
    "    close_data = close_cache[cache_key]\n",
    "    close_data = close_data[~close_data.index.duplicated(keep = 'first')]\n",
    "    close = close_data['Midpoint'][date]\n",
    "    return close\n",
    "\n",
    "\n",
    "def load_chain(date, ticker,  print_stderr = False):\n",
    "        print(date, ticker) if print_stderr else None\n",
    "        ## Get both calls and puts per moneyness. For 1 Moneyness, both will most be available. If not, if one is False, other True. \n",
    "        ## We will need to get two rows. \n",
    "        chain_key = f\"{date}_{ticker}\"\n",
    "        with Context(end_date = date):\n",
    "            if chain_key in chain_cache:\n",
    "                Option_Chain = chain_cache[chain_key]\n",
    "            else:\n",
    "                start_time = time.time()\n",
    "                Stock_obj = Stock(ticker, run_chain = False)\n",
    "                end_time = time.time()\n",
    "                print(f\"Time taken to get stock object: {end_time-start_time}\") if print_stderr else None\n",
    "                Option_Chain = Stock_obj.option_chain()\n",
    "                Spot = Stock_obj.spot(ts = False)\n",
    "                Spot = list(Spot.values())[0]\n",
    "                Option_Chain['Spot'] = Spot\n",
    "                Option_Chain['q'] = Stock_obj.div_yield()\n",
    "                Option_Chain['r'] = Stock_obj.rf_rate\n",
    "                chain_cache[chain_key] = Option_Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_cache(order_candidates, date = '2024-03-12',):\n",
    "\n",
    "    global close_cache, oi_cache, spot_cache\n",
    "\n",
    "    tempholder1 = {}\n",
    "    tempholder2 = {}\n",
    "\n",
    "    ## Create necessary data structures\n",
    "    ## Looping through the order candidates to get the necessary data, and organize into a list of lists that will be passed to runProcesses function\n",
    "    for j, direction in enumerate(order_candidates):\n",
    "        for i,data in enumerate(order_candidates[direction]):\n",
    "            data[[ 'exp', 'strike', 'symbol']] = data[[ 'expiration', 'strike', 'ticker']]\n",
    "            start = (pd.to_datetime(date) - BDay(20)).strftime('%Y-%m-%d')\n",
    "            data[['end_date', 'start_date']] = date, start\n",
    "            data['exp'] = data['exp'].dt.strftime('%Y-%m-%d')\n",
    "            tempholder1[i+j] = (data[['symbol', 'end_date', 'exp', 'right', 'start_date', 'strike']].T.values.tolist())\n",
    "            tempholder2[i+j] = data[['symbol', 'right', 'exp','strike']].T.values.tolist()\n",
    "\n",
    "    ## Extending lists, to ensure only one runProcesses call is made, instead of run per side\n",
    "    for i, data in tempholder1.items():\n",
    "        if i == 0:\n",
    "            OrderedList = data\n",
    "            tickOrderedList = tempholder2[i]\n",
    "        else:\n",
    "            for position, vars in enumerate(data):\n",
    "                OrderedList[position].extend(vars)\n",
    "            for position, vars in enumerate(tempholder2[i]):\n",
    "                tickOrderedList[position].extend(vars)\n",
    "\n",
    "    \n",
    "    eod_results = (runProcesses(retrieve_eod_ohlc, OrderedList, 'imap'))\n",
    "    oi_results = (runProcesses(retrieve_openInterest, OrderedList, 'imap'))\n",
    "    tick_results = (runProcesses(generate_option_tick, tickOrderedList, 'imap'))\n",
    "    tick_results = list(set(tick_results))\n",
    "\n",
    "\n",
    "    ## Save to Dictionary Cache\n",
    "    for tick, eod, oi in zip(tick_results, eod_results, oi_results):\n",
    "        cache_key = f\"{tick}_{date}\"\n",
    "        close_cache[cache_key] = eod\n",
    "        oi_cache[cache_key] = oi\n",
    "\n",
    "\n",
    "    ## Test1: Run spot_cache process after close_cache has been populate.\n",
    "    \n",
    "    spot_results = list(runProcesses(return_closePrice, [tick_results, [date]*len(tick_results)], 'imap'))   \n",
    "    for tick, spot in zip(tick_results, spot_results):\n",
    "        cache_key = f\"{tick}_{date}\"\n",
    "        spot_cache[cache_key] = spot\n",
    "\n",
    "\n",
    "    ## Test2: We will edit the populate spot_cache populate function to make an api call instead of using the cache.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_order_candidates(settings, tick, date, right = 'P'):\n",
    "    order_candidates = {'long': [], 'short': []}\n",
    "    for spec in settings['specifics']:\n",
    "        order_candidates[spec['direction']].append(chain_details(date, tick, spec['dte'], spec['rel_strike'], right,  moneyness_width = spec['moneyness_width']))\n",
    "    return order_candidates\n",
    "\n",
    "\n",
    "def liquidity_check(id, date, pass_threshold = 250):\n",
    "    sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "    new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "    transfer_dict = {}\n",
    "    for k, v in sample_id.items():\n",
    "\n",
    "        if k in new_dict_keys:\n",
    "            if k == 'strike':\n",
    "                transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "            else:\n",
    "                transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "\n",
    "    start = (pd.to_datetime(date) - BDay(10)).strftime('%Y-%m-%d')\n",
    "    oi_data = retrieve_openInterest(**transfer_dict, end_date=date, start_date=start)\n",
    "    # print(f'Open Interest > {pass_threshold} for {id}:', oi_data.Open_interest.mean() )\n",
    "    return oi_data.Open_interest.mean() > pass_threshold\n",
    "\n",
    "\n",
    "def available_close_check(id, date, threshold = 0.7):\n",
    "    cache_key = f\"{id}_{date}\"\n",
    "    sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "    new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "    transfer_dict = {}\n",
    "    for k, v in sample_id.items():\n",
    "        if k in new_dict_keys:\n",
    "            if k == 'strike':\n",
    "                transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "            else:\n",
    "                transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "    \n",
    "    if cache_key in close_cache:\n",
    "        close_data_sample = close_cache[cache_key]\n",
    "    else:\n",
    "        start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "        close_data_sample = retrieve_eod_ohlc(**transfer_dict, start_date=start, end_date=date)\n",
    "        close_cache[cache_key] = close_data_sample\n",
    "    close_mask_series = close_data_sample.Close != 0\n",
    "    return close_mask_series.sum()/len(close_mask_series) > threshold\n",
    "\n",
    "\n",
    "def get_structure_price(tradeables, direction_index, date, tick, right = 'P'):\n",
    "    pack_price = {}\n",
    "    pack_dataframe = pd.DataFrame()\n",
    "    pack_dataframe['close'] = 0\n",
    "\n",
    "    for pack_i, pack in enumerate(tradeables):\n",
    "        pack_close = 0\n",
    "        for i, id in enumerate(pack):\n",
    "            if id not in spot_cache:\n",
    "                \n",
    "                cache_key = f\"{id}_{date}\"\n",
    "                sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "                new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "                transfer_dict = {}\n",
    "                for k, v in sample_id.items():\n",
    "                    if k in new_dict_keys:\n",
    "                        if k == 'strike':\n",
    "                            transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "                        else:\n",
    "                            transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "                start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "                close_data_sample = retrieve_eod_ohlc(**transfer_dict, start_date=start, end_date=date)\n",
    "                close_data_sample = close_data_sample[~close_data_sample.index.duplicated(keep = 'first')]\n",
    "                close = close_data_sample['Midpoint'][date]\n",
    "                spot_cache[cache_key] = close\n",
    "            else:\n",
    "                close = cache_key[id]\n",
    "            pack_close += close * direction_index[i]\n",
    "            pack_dataframe.at[pack_i, i] = id\n",
    "\n",
    "        pack_dataframe.at[pack_i, 'close'] = pack_close\n",
    "    return pack_dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_details(date, ticker, tgt_dte, tgt_moneyness, right = 'P', moneyness_width = 0.15, print_stderr = False):\n",
    "    return_dataframe = pd.DataFrame()\n",
    "    errors = {}\n",
    "    if not (is_USholiday(date) and not is_busday(date)):\n",
    "        try:\n",
    "            print(date, ticker) if print_stderr else None\n",
    "            ## Get both calls and puts per moneyness. For 1 Moneyness, both will most be available. If not, if one is False, other True. \n",
    "            ## We will need to get two rows. \n",
    "            chain_key = f\"{date}_{ticker}\"\n",
    "            with Context(end_date = date):\n",
    "                if chain_key in chain_cache:\n",
    "                    Option_Chain = chain_cache[chain_key]\n",
    "                else:\n",
    "                    start_time = time.time()\n",
    "                    Stock_obj = Stock(ticker, run_chain = False)\n",
    "                    end_time = time.time()\n",
    "                    print(f\"Time taken to get stock object: {end_time-start_time}\") if print_stderr else None\n",
    "                    Option_Chain = Stock_obj.option_chain()\n",
    "                    Spot = Stock_obj.spot(ts = False)\n",
    "                    Spot = list(Spot.values())[0]\n",
    "                    Option_Chain['Spot'] = Spot\n",
    "                    Option_Chain['q'] = Stock_obj.div_yield()\n",
    "                    Option_Chain['r'] = Stock_obj.rf_rate\n",
    "                    chain_cache[chain_key] = Option_Chain\n",
    "\n",
    "                \n",
    "                Option_Chain_Filtered = Option_Chain[Option_Chain[right.upper()] == True]\n",
    "                \n",
    "                \n",
    "                if right == 'P':\n",
    "                    Option_Chain_Filtered['relative_moneyness']  = Option_Chain_Filtered.index.get_level_values('strike')/Option_Chain_Filtered.Spot\n",
    "                elif right == 'C':\n",
    "                    Option_Chain_Filtered['relative_moneyness']  = Option_Chain_Filtered.Spot/Option_Chain_Filtered.index.get_level_values('strike')\n",
    "                else:\n",
    "                    raise ValueError(f'Right dne. recieved {right}')\n",
    "                Option_Chain_Filtered['moneyness_spread'] = (tgt_moneyness-Option_Chain_Filtered['relative_moneyness'])**2\n",
    "                Option_Chain_Filtered['dte_spread'] = (Option_Chain_Filtered.index.get_level_values('DTE')-tgt_dte)**2\n",
    "                Option_Chain_Filtered.sort_values(by=['dte_spread','moneyness_spread'], inplace = True)\n",
    "                Option_Chain_Filtered = Option_Chain_Filtered.loc[Option_Chain_Filtered['dte_spread'] == Option_Chain_Filtered['dte_spread'].min()]\n",
    "                if float(moneyness_width) == 0.0:\n",
    "                    option_details = Option_Chain_Filtered.sort_values('moneyness_spread', ascending=False).head(1)\n",
    "                else:\n",
    "                    option_details = Option_Chain_Filtered[(Option_Chain_Filtered['relative_moneyness'] >= tgt_moneyness-moneyness_width) & \n",
    "                                                        (Option_Chain_Filtered['relative_moneyness'] <= tgt_moneyness+moneyness_width)]\n",
    "                option_details['build_date'] = date\n",
    "                option_details['ticker'] = ticker\n",
    "                option_details['moneyness'] = tgt_moneyness\n",
    "                option_details['TGT_DTE'] = tgt_dte\n",
    "                option_details.reset_index(inplace = True)\n",
    "                option_details.set_index('build_date', inplace = True)\n",
    "                option_details['right'] = right\n",
    "                option_details.drop(columns = ['C','P'], inplace = True)\n",
    "                option_details['option_id'] = option_details.apply(lambda x: generate_option_tick(symbol = x['ticker'], \n",
    "                                                                    exp = x['expiration'].strftime('%Y-%m-%d'), strike = float(x['strike']), right = x['right']), axis = 1)\n",
    "                return_dataframe = pd.concat([return_dataframe, option_details])\n",
    "            clear_context()\n",
    "            return_dataframe.drop_duplicates(inplace = True)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise\n",
    "\n",
    "        return return_dataframe.sort_values('relative_moneyness', ascending=False)\n",
    "    else:\n",
    "        return None, errors\n",
    "    \n",
    "\n",
    "details= chain_details('2024-03-12', 'TSLA', 365, 0.7, moneyness_width = 0.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING ORDERPICKER AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['TSLA20250321000190C'],\n",
       " 'S': ['TSLA20250321000205C'],\n",
       " 'trade_id': '&L:TSLA20250321000190C&S:TSLA20250321000205C',\n",
       " 'close': 4.025000000000006}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OrderPicker:\n",
    "    def __init__(self):\n",
    "        self.liquidity_threshold = 250\n",
    "        self.data_availability_threshold = 0.7\n",
    "        self.lookback = 30\n",
    "\n",
    "    def get_order(self, \n",
    "                  tick, \n",
    "                  date,\n",
    "                  right, \n",
    "                  max_close,\n",
    "                  order_settings):\n",
    "        \n",
    "        ## Create necessary data structures\n",
    "        direction_index = {}\n",
    "        str_direction_index = {}\n",
    "        for indx, v in enumerate(order_settings['specifics']):\n",
    "            if v['direction'] == 'long':\n",
    "                str_direction_index[indx] = 'L'\n",
    "                direction_index[indx] = 1\n",
    "            elif v['direction'] == 'short':\n",
    "                str_direction_index[indx] = 'S'\n",
    "                direction_index[indx] = -1\n",
    "\n",
    "\n",
    "        load_chain(date, 'TSLA')\n",
    "        order_candidates = produce_order_candidates(order_settings, tick, date, right)\n",
    "\n",
    "\n",
    "        populate_cache(order_candidates, date=date)\n",
    "\n",
    "\n",
    "        for direction in order_candidates:\n",
    "            for i,data in enumerate(order_candidates[direction]):\n",
    "                data['liquidity_check'] = data.option_id.apply(lambda x: liquidity_check(x, date))\n",
    "                data = data[data.liquidity_check == True]\n",
    "                data['available_close_check'] = data.option_id.apply(lambda x: available_close_check(x, date))\n",
    "                order_candidates[direction][i] = data[data.available_close_check == True] \n",
    "\n",
    "\n",
    "\n",
    "        ## Filter Unique Combinations per leg.\n",
    "        unique_ids = {'long': [], 'short': []}\n",
    "        for direction in order_candidates:\n",
    "            for i,data in enumerate(order_candidates[direction]):\n",
    "                unique_ids[direction].append(data[(data.liquidity_check == True) & (data.available_close_check == True)].option_id.unique().tolist())\n",
    "\n",
    "        ## Produce Tradeable Combinations\n",
    "        tradeable_ids = list(product(*unique_ids['long'], *unique_ids['short']))\n",
    "        tradeable_ids, unique_ids \n",
    "\n",
    "        ## Keep only unique combinations. Not repeating a contract.\n",
    "        filtered = [t for t in tradeable_ids if len(set(t)) == len(t)]\n",
    "\n",
    "        ## Get the price of the structure\n",
    "        ## Using List Comprehension to sum the prices of the structure per index\n",
    "        results = [\n",
    "            (*items, sum([direction_index[i] * spot_cache[f'{item}_{date}'] for i, item in enumerate(items)])) for items in filtered\n",
    "        ]\n",
    "\n",
    "        ## Convert to DataFrame, and sort by the price of the structure.\n",
    "        return_dataframe = pd.DataFrame(results)\n",
    "        cols = return_dataframe.columns.tolist()\n",
    "        cols[-1] = 'close'\n",
    "        return_dataframe.columns= cols\n",
    "        return_dataframe = return_dataframe[(return_dataframe.close<= max_close) & (return_dataframe.close> 0)].sort_values('close', ascending = False).head(1)\n",
    "\n",
    "        ## Rename the columns to the direction names\n",
    "        return_dataframe.columns = list(str_direction_index.values()) + ['close']\n",
    "        return_order = return_dataframe[list(str_direction_index.values())].to_dict(orient = 'list')\n",
    "        return_order\n",
    "\n",
    "        ## Create the trade_id with the direction and the id of the contract.\n",
    "        id = ''\n",
    "        for k, v in return_order.items():\n",
    "            id += f\"&{k}:{v[0]}\"\n",
    "\n",
    "        return_order['trade_id'] = id\n",
    "        return_order['close'] = return_dataframe.close.values[0]\n",
    "\n",
    "        return return_order\n",
    "\n",
    "\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.10},\n",
    "                {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.10} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }\n",
    "\n",
    "\n",
    "tick = 'TSLA'\n",
    "date = '2024-03-12'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'P'\n",
    "\n",
    "\n",
    "picker = OrderPicker()\n",
    "er = picker.get_order(tick, date, 'C', 10, order_settings)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['TSLA20250321000165C'],\n",
       " 'S': ['TSLA20250321000200C'],\n",
       " 'trade_id': '&L:TSLA20250321000165C&S:TSLA20250321000200C',\n",
       " 'close': 9.674999999999997}"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RiskManager:\n",
    "    def __init__(self,\n",
    "                 bars,\n",
    "                 events,\n",
    "                 initial_capital,\n",
    "                 ):\n",
    "        self.bars = bars\n",
    "        self.events = events\n",
    "        self.initial_capital = initial_capital\n",
    "        # self.symbol_list = self.bars.symbol_list\n",
    "        self.OrderPicker = OrderPicker()\n",
    "\n",
    "\n",
    "    def get_order(self, symbol, date, order_settings):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "rm = RiskManager(None, None, 1000000)\n",
    "rm.OrderPicker.get_order(tick, date, 'C', 10, order_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRY RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas_market_calendars/market_calendar.py:561\u001b[0m, in \u001b[0;36mMarketCalendar.holidays\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_holidays\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NYSEExchangeCalendar' object has no attribute '_holidays'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m         direction_index[indx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     27\u001b[0m load_chain(date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSLA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m order_candidates \u001b[38;5;241m=\u001b[39m \u001b[43mproduce_order_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtick\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m populate_cache(order_candidates, date\u001b[38;5;241m=\u001b[39mdate)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m direction \u001b[38;5;129;01min\u001b[39;00m order_candidates:\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mproduce_order_candidates\u001b[0;34m(settings, tick, date, right)\u001b[0m\n\u001b[1;32m      2\u001b[0m order_candidates \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecifics\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     order_candidates[spec[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirection\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mchain_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtick\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdte\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrel_strike\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmoneyness_width\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmoneyness_width\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m order_candidates\n",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m, in \u001b[0;36mchain_details\u001b[0;34m(date, ticker, tgt_dte, tgt_moneyness, right, moneyness_width, print_stderr)\u001b[0m\n\u001b[1;32m      2\u001b[0m return_dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      3\u001b[0m errors \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43mis_USholiday\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_busday(date)):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(date, ticker) \u001b[38;5;28;01mif\u001b[39;00m print_stderr \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/cloned_repos/QuantTools/trade/helpers/helper.py:681\u001b[0m, in \u001b[0;36mis_USholiday\u001b[0;34m(date)\u001b[0m\n\u001b[1;32m    679\u001b[0m nyse \u001b[38;5;241m=\u001b[39m mcal\u001b[38;5;241m.\u001b[39mget_calendar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNYSE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    680\u001b[0m date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mnyse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_days\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas_market_calendars/calendars/nyse.py:1285\u001b[0m, in \u001b[0;36mNYSEExchangeCalendar.valid_days\u001b[0;34m(self, start_date, end_date, tz)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalid_days\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_date, end_date, tz\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;124;03m    Get a DatetimeIndex of valid open business days.\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03m    :return: DatetimeIndex of valid business days\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m     trading_days \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_days\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;66;03m# Starting Monday Sept. 29, 1952, no more saturday trading days\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas_market_calendars/market_calendar.py:580\u001b[0m, in \u001b[0;36mMarketCalendar.valid_days\u001b[0;34m(self, start_date, end_date, tz)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalid_days\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_date, end_date, tz\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    Get a DatetimeIndex of valid open business days.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    :return: DatetimeIndex of valid business days\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mdate_range(\n\u001b[0;32m--> 580\u001b[0m         start_date, end_date, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mholidays\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, tz\u001b[38;5;241m=\u001b[39mtz\n\u001b[1;32m    581\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas_market_calendars/market_calendar.py:563\u001b[0m, in \u001b[0;36mMarketCalendar.holidays\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_holidays\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_holidays \u001b[38;5;241m=\u001b[39m \u001b[43mCustomBusinessDay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mholidays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madhoc_holidays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalendar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregular_holidays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweekmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweekmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_holidays\n",
      "File \u001b[0;32moffsets.pyx:4301\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.CustomBusinessDay.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:1706\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.BusinessMixin._init_custom\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:219\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets._get_calendar\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas/tseries/holiday.py:476\u001b[0m, in \u001b[0;36mAbstractHolidayCalendar.holidays\u001b[0;34m(self, start, end, return_name)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# If we don't have a cache or the dates are outside the prior cache, we\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# get them again\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m start \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m end \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 476\u001b[0m     pre_holidays \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrules\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pre_holidays:\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"concat\" has incompatible type\u001b[39;00m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;66;03m# \"List[Union[Series, DatetimeIndex]]\"; expected\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;66;03m# \"Union[Iterable[DataFrame], Mapping[<nothing>, DataFrame]]\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m         holidays \u001b[38;5;241m=\u001b[39m concat(pre_holidays)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas/tseries/holiday.py:477\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# If we don't have a cache or the dates are outside the prior cache, we\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# get them again\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m start \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m end \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    476\u001b[0m     pre_holidays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 477\u001b[0m         \u001b[43mrule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrules\n\u001b[1;32m    478\u001b[0m     ]\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pre_holidays:\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"concat\" has incompatible type\u001b[39;00m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;66;03m# \"List[Union[Series, DatetimeIndex]]\"; expected\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;66;03m# \"Union[Iterable[DataFrame], Mapping[<nothing>, DataFrame]]\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m         holidays \u001b[38;5;241m=\u001b[39m concat(pre_holidays)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas/tseries/holiday.py:282\u001b[0m, in \u001b[0;36mHoliday.dates\u001b[0;34m(self, start_date, end_date, return_name)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dti\n\u001b[0;32m--> 282\u001b[0m dates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reference_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m holiday_dates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_rule(dates)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdays_of_week \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas/tseries/holiday.py:334\u001b[0m, in \u001b[0;36mHoliday._reference_dates\u001b[0;34m(self, start_date, end_date)\u001b[0m\n\u001b[1;32m    330\u001b[0m reference_end_date \u001b[38;5;241m=\u001b[39m Timestamp(\n\u001b[1;32m    331\u001b[0m     datetime(end_date\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mday)\n\u001b[1;32m    332\u001b[0m )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Don't process unnecessary holidays\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m dates \u001b[38;5;241m=\u001b[39m \u001b[43mdate_range\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_start_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_end_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myear_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dates\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:1008\u001b[0m, in \u001b[0;36mdate_range\u001b[0;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m com\u001b[38;5;241m.\u001b[39many_none(periods, start, end):\n\u001b[1;32m   1006\u001b[0m     freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1008\u001b[0m dtarr \u001b[38;5;241m=\u001b[39m \u001b[43mDatetimeArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_range\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperiods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclusive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclusive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndex\u001b[38;5;241m.\u001b[39m_simple_new(dtarr, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/openbb/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:468\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[0;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     xdr \u001b[38;5;241m=\u001b[39m _generate_range(\n\u001b[1;32m    466\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, periods\u001b[38;5;241m=\u001b[39mperiods, offset\u001b[38;5;241m=\u001b[39mfreq, unit\u001b[38;5;241m=\u001b[39munit\n\u001b[1;32m    467\u001b[0m     )\n\u001b[0;32m--> 468\u001b[0m     i8values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([x\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xdr], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    470\u001b[0m endpoint_tz \u001b[38;5;241m=\u001b[39m start\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m end\u001b[38;5;241m.\u001b[39mtz\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m endpoint_tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_close = 5\n",
    "\n",
    "\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.01},\n",
    "                {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.01} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "direction_index = {}\n",
    "str_direction_index = {}\n",
    "for indx, v in enumerate(order_settings['specifics']):\n",
    "    if v['direction'] == 'long':\n",
    "        str_direction_index[indx] = 'L'\n",
    "        direction_index[indx] = 1\n",
    "    elif v['direction'] == 'short':\n",
    "        str_direction_index[indx] = 'S'\n",
    "        direction_index[indx] = -1\n",
    "\n",
    "\n",
    "load_chain(date, 'TSLA')\n",
    "order_candidates = produce_order_candidates(order_settings, tick, date, right)\n",
    "\n",
    "\n",
    "populate_cache(order_candidates, date=date)\n",
    "\n",
    "\n",
    "for direction in order_candidates:\n",
    "    for i,data in enumerate(order_candidates[direction]):\n",
    "        data['liquidity_check'] = data.option_id.apply(lambda x: liquidity_check(x, date))\n",
    "        data = data[data.liquidity_check == True]\n",
    "        data['available_close_check'] = data.option_id.apply(lambda x: available_close_check(x, date))\n",
    "        order_candidates[direction][i] = data[data.available_close_check == True] \n",
    "\n",
    "\n",
    "\n",
    "## Filter Unique Combinations per leg.\n",
    "unique_ids = {'long': [], 'short': []}\n",
    "for direction in order_candidates:\n",
    "    for i,data in enumerate(order_candidates[direction]):\n",
    "        unique_ids[direction].append(data[(data.liquidity_check == True) & (data.available_close_check == True)].option_id.unique().tolist())\n",
    "\n",
    "## Produce Tradeable Combinations\n",
    "tradeable_ids = list(product(*unique_ids['long'], *unique_ids['short']))\n",
    "tradeable_ids, unique_ids \n",
    "\n",
    "## Keep only unique combinations. Not repeating a contract.\n",
    "filtered = [t for t in tradeable_ids if len(set(t)) == len(t)]\n",
    "\n",
    "## Get the price of the structure\n",
    "## Using List Comprehension to sum the prices of the structure per index\n",
    "results = [\n",
    "    (*items, sum([direction_index[i] * spot_cache[f'{item}_{date}'] for i, item in enumerate(items)])) for items in filtered\n",
    "]\n",
    "\n",
    "## Convert to DataFrame, and sort by the price of the structure.\n",
    "return_dataframe = pd.DataFrame(results)\n",
    "cols = return_dataframe.columns.tolist()\n",
    "cols[-1] = 'close'\n",
    "return_dataframe.columns= cols\n",
    "return_dataframe = return_dataframe[(return_dataframe.close<= max_close) & (return_dataframe.close> 0)].sort_values('close', ascending = False).head(1)\n",
    "\n",
    "## Rename the columns to the direction names\n",
    "return_dataframe.columns = list(str_direction_index.values()) + ['close']\n",
    "return_order = return_dataframe[list(str_direction_index.values())].to_dict(orient = 'list')\n",
    "return_order\n",
    "\n",
    "## Create the trade_id with the direction and the id of the contract.\n",
    "id = ''\n",
    "for k, v in return_order.items():\n",
    "    id += f\"&{k}:{v[0]}\"\n",
    "\n",
    "return_order['trade_id'] = id\n",
    "return_order['close'] = return_dataframe.close.values[0]\n",
    "\n",
    "return_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>S</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [L, S, close]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task: https://api.github.com\n",
      "Starting task: https://api.spacexdata.com/v4/launches/latest\n",
      "Starting task: https://jsonplaceholder.typicode.com/todos/1\n",
      "Completed task: https://api.github.com\n",
      "Completed task: https://api.spacexdata.com/v4/launches/latest\n",
      "Completed task: https://jsonplaceholder.typicode.com/todos/1\n",
      "{'current_user_url': 'https://api.github.com/user', 'current_user_authorizations_html_url': 'https://github.com/settings/connections/applications{/client_id}', 'authorizations_url': 'https://api.github.com/authorizations', 'code_search_url': 'https://api.github.com/search/code?q={query}{&page,per_page,sort,order}', 'commit_search_url': 'https://api.github.com/search/commits?q={query}{&page,per_page,sort,order}', 'emails_url': 'https://api.github.com/user/emails', 'emojis_url': 'https://api.github.com/emojis', 'events_url': 'https://api.github.com/events', 'feeds_url': 'https://api.github.com/feeds', 'followers_url': 'https://api.github.com/user/followers', 'following_url': 'https://api.github.com/user/following{/target}', 'gists_url': 'https://api.github.com/gists{/gist_id}', 'hub_url': 'https://api.github.com/hub', 'issue_search_url': 'https://api.github.com/search/issues?q={query}{&page,per_page,sort,order}', 'issues_url': 'https://api.github.com/issues', 'keys_url': 'https://api.github.com/user/keys', 'label_search_url': 'https://api.github.com/search/labels?q={query}&repository_id={repository_id}{&page,per_page}', 'notifications_url': 'https://api.github.com/notifications', 'organization_url': 'https://api.github.com/orgs/{org}', 'organization_repositories_url': 'https://api.github.com/orgs/{org}/repos{?type,page,per_page,sort}', 'organization_teams_url': 'https://api.github.com/orgs/{org}/teams', 'public_gists_url': 'https://api.github.com/gists/public', 'rate_limit_url': 'https://api.github.com/rate_limit', 'repository_url': 'https://api.github.com/repos/{owner}/{repo}', 'repository_search_url': 'https://api.github.com/search/repositories?q={query}{&page,per_page,sort,order}', 'current_user_repositories_url': 'https://api.github.com/user/repos{?type,page,per_page,sort}', 'starred_url': 'https://api.github.com/user/starred{/owner}{/repo}', 'starred_gists_url': 'https://api.github.com/gists/starred', 'topic_search_url': 'https://api.github.com/search/topics?q={query}{&page,per_page}', 'user_url': 'https://api.github.com/users/{user}', 'user_organizations_url': 'https://api.github.com/user/orgs', 'user_repositories_url': 'https://api.github.com/users/{user}/repos{?type,page,per_page,sort}', 'user_search_url': 'https://api.github.com/search/users?q={query}{&page,per_page,sort,order}'}\n",
      "{'fairings': None, 'links': {'patch': {'small': 'https://images2.imgbox.com/eb/d8/D1Yywp0w_o.png', 'large': 'https://images2.imgbox.com/33/2e/k6VE4iYl_o.png'}, 'reddit': {'campaign': None, 'launch': 'https://www.reddit.com/r/spacex/comments/xvm76j/rspacex_crew5_launchcoast_docking_discussion_and/', 'media': None, 'recovery': None}, 'flickr': {'small': [], 'original': []}, 'presskit': None, 'webcast': 'https://youtu.be/5EwW8ZkArL4', 'youtube_id': '5EwW8ZkArL4', 'article': None, 'wikipedia': 'https://en.wikipedia.org/wiki/SpaceX_Crew-5'}, 'static_fire_date_utc': None, 'static_fire_date_unix': None, 'net': False, 'window': None, 'rocket': '5e9d0d95eda69973a809d1ec', 'success': True, 'failures': [], 'details': None, 'crew': ['62dd7196202306255024d13c', '62dd71c9202306255024d13d', '62dd7210202306255024d13e', '62dd7253202306255024d13f'], 'ships': [], 'capsules': ['617c05591bad2c661a6e2909'], 'payloads': ['62dd73ed202306255024d145'], 'launchpad': '5e9e4502f509094188566f88', 'flight_number': 187, 'name': 'Crew-5', 'date_utc': '2022-10-05T16:00:00.000Z', 'date_unix': 1664985600, 'date_local': '2022-10-05T12:00:00-04:00', 'date_precision': 'hour', 'upcoming': False, 'cores': [{'core': '633d9da635a71d1d9c66797b', 'flight': 1, 'gridfins': True, 'legs': True, 'reused': False, 'landing_attempt': True, 'landing_success': True, 'landing_type': 'ASDS', 'landpad': '5e9e3033383ecbb9e534e7cc'}], 'auto_update': True, 'tbd': False, 'launch_library_id': 'f33d5ece-e825-4cd8-809f-1d4c72a2e0d3', 'id': '62dd70d5202306255024d139'}\n",
      "{'userId': 1, 'id': 1, 'title': 'delectus aut autem', 'completed': False}\n",
      "Total time taken: 0.1384739875793457 seconds\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def fetch_data(session, url):\n",
    "    print(f\"Starting task: {url}\")\n",
    "    async with session.get(url) as response:\n",
    "        data = await response.json()\n",
    "        print(f\"Completed task: {url}\")\n",
    "        return data\n",
    "\n",
    "async def main():\n",
    "    urls = [\n",
    "        'https://api.github.com',\n",
    "        'https://api.spacexdata.com/v4/launches/latest',\n",
    "        'https://jsonplaceholder.typicode.com/todos/1'\n",
    "    ]\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_data(session, url) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for result in results:\n",
    "            print(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    asyncio.run(main())\n",
    "    print(f\"Total time taken: {time.time() - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to producing an order:\n",
    "\n",
    "- S1: RM recieves order settings from PM\n",
    "- S2: RM produces a dataframe of potential options based on settings (if two legs produce two dataframes)\n",
    "- S3: RM assesses if option passes all checks\n",
    "    - C1: Minimum Available close\n",
    "    - C2: Liquidity (Open Interest)\n",
    "    - C2.5: (for Spreads only) Ensure both legs are not the same\n",
    "    - Optional, to extend:\n",
    "    - C3: Bid-Ask Spread\n",
    "    \n",
    "- S4: Return picked order to portfolio manager, which places the order. \n",
    "- Example:\n",
    "    {'long': [optionid or {'strike', 'exp'}], 'short' : []}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openbb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
