{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "os.environ['STREAM_LOG_LEVEL'] = 'ERROR'\n",
    "os.environ['FILE_LOG_LEVEL'] = 'DEBUG'\n",
    "os.environ['PROPAGATE_TO_ROOT_LOGGER'] = 'False'\n",
    "os.environ['PROPAGATE_TO_ROOT_LOGGER'], os.environ['STREAM_LOG_LEVEL']\n",
    "from trade.assets.Stock import Stock\n",
    "from trade.assets.Option import Option\n",
    "from trade.assets.OptionStructure import OptionStructure\n",
    "from trade.helpers.Context import Context, clear_context\n",
    "from trade.helpers.helper import (change_to_last_busday, \n",
    "                                  is_USholiday, \n",
    "                                  is_busday, \n",
    "                                  setup_logger, \n",
    "                                  generate_option_tick, \n",
    "                                  get_option_specifics_from_key,\n",
    "                                  identify_length,\n",
    "                                  extract_numeric_value)\n",
    "from scipy.stats import percentileofscore\n",
    "from EventDriven.riskmanager import RiskManager\n",
    "from dbase.DataAPI.ThetaData import (list_contracts, retrieve_openInterest, retrieve_eod_ohlc, retrieve_quote)\n",
    "from pandas.tseries.offsets import BDay\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import numpy as np\n",
    "import time\n",
    "chain_cache = {}\n",
    "close_cache = {}\n",
    "oi_cache = {}\n",
    "spot_cache = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['BAC20250321000032C'],\n",
       " 'S': ['BAC20250321000037C'],\n",
       " 'trade_id': '&L:BAC20250321000032C&S:BAC20250321000037C',\n",
       " 'close': 1.2300000000000004}"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EventDriven.riskmanager import RiskManager\n",
    "\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.15},\n",
    "                {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.15} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }\n",
    "tick = 'BAC'\n",
    "date = '2024-03-12'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'P'\n",
    "\n",
    "rm = RiskManager(None, None, 1000000)\n",
    "rm.OrderPicker.get_order(tick, date, 'C', 7.5, order_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLE ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = 'BAC'\n",
    "date = '2023-07-24'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'C'\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.15},\n",
    "                # {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.15} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTIPROCESSING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from abc import ABC, abstractmethod\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from pathos.multiprocessing import cpu_count\n",
    "from pathos.pools import _ProcessPool\n",
    "from threading import Thread\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "shutdown_event = False\n",
    "\n",
    "def runProcesses(func, OrderedInputs: List[List], run_type: str = 'map') -> List:\n",
    "    try:\n",
    "\n",
    "        pool = Pool(20)\n",
    "        pool.restart()\n",
    "        if run_type == 'map':\n",
    "            results = pool.map(func, *OrderedInputs)\n",
    "        elif run_type == 'amap':\n",
    "            results = pool.amap(func, *OrderedInputs)\n",
    "        elif run_type == 'uimap':\n",
    "            results = pool.uimap(func, *OrderedInputs)\n",
    "        elif run_type == 'imap':\n",
    "            results = pool.imap(func, *OrderedInputs)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'Run type {run_type} not recognized')\n",
    "\n",
    "    except KeyboardInterrupt as e:\n",
    "\n",
    "        shutdown_event = True\n",
    "        shutdown(pool)\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error occured: ', e)\n",
    "        shutdown(pool)\n",
    "\n",
    "\n",
    "    finally:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def shutdown(pool):\n",
    "    global shutdown_event\n",
    "    shutdown_event\n",
    "    shutdown_event = True\n",
    "    pool.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELEVANT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_closePrice(id, date):\n",
    "    global close_cache, spot_cache\n",
    "    cache_key = f\"{id}_{date}\"\n",
    "    close_data = close_cache[cache_key]\n",
    "    close_data = close_data[~close_data.index.duplicated(keep = 'first')]\n",
    "    close = close_data['Midpoint'][date]\n",
    "    return close\n",
    "\n",
    "\n",
    "def load_chain(date, ticker,  print_stderr = False):\n",
    "        print(date, ticker) if print_stderr else None\n",
    "        ## Get both calls and puts per moneyness. For 1 Moneyness, both will most be available. If not, if one is False, other True. \n",
    "        ## We will need to get two rows. \n",
    "        chain_key = f\"{date}_{ticker}\"\n",
    "        with Context(end_date = date):\n",
    "            if chain_key in chain_cache:\n",
    "                Option_Chain = chain_cache[chain_key]\n",
    "            else:\n",
    "                start_time = time.time()\n",
    "                Stock_obj = Stock(ticker, run_chain = False)\n",
    "                end_time = time.time()\n",
    "                print(f\"Time taken to get stock object: {end_time-start_time}\") if print_stderr else None\n",
    "                Option_Chain = Stock_obj.option_chain()\n",
    "                Spot = Stock_obj.spot(ts = False)\n",
    "                Spot = list(Spot.values())[0]\n",
    "                Option_Chain['Spot'] = Spot\n",
    "                Option_Chain['q'] = Stock_obj.div_yield()\n",
    "                Option_Chain['r'] = Stock_obj.rf_rate\n",
    "                chain_cache[chain_key] = Option_Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_cache(order_candidates, date = '2024-03-12',):\n",
    "\n",
    "    global close_cache, oi_cache, spot_cache\n",
    "\n",
    "    tempholder1 = {}\n",
    "    tempholder2 = {}\n",
    "\n",
    "    ## Create necessary data structures\n",
    "    ## Looping through the order candidates to get the necessary data, and organize into a list of lists that will be passed to runProcesses function\n",
    "    for j, direction in enumerate(order_candidates):\n",
    "        for i,data in enumerate(order_candidates[direction]):\n",
    "            data[[ 'exp', 'strike', 'symbol']] = data[[ 'expiration', 'strike', 'ticker']]\n",
    "            start = (pd.to_datetime(date) - BDay(20)).strftime('%Y-%m-%d')\n",
    "            data[['end_date', 'start_date']] = date, start\n",
    "            data['exp'] = data['exp'].dt.strftime('%Y-%m-%d')\n",
    "            tempholder1[i+j] = (data[['symbol', 'end_date', 'exp', 'right', 'start_date', 'strike']].T.values.tolist())\n",
    "            tempholder2[i+j] = data[['symbol', 'right', 'exp','strike']].T.values.tolist()\n",
    "\n",
    "    ## Extending lists, to ensure only one runProcesses call is made, instead of run per side\n",
    "    for i, data in tempholder1.items():\n",
    "        if i == 0:\n",
    "            OrderedList = data\n",
    "            tickOrderedList = tempholder2[i]\n",
    "        else:\n",
    "            for position, vars in enumerate(data):\n",
    "                OrderedList[position].extend(vars)\n",
    "            for position, vars in enumerate(tempholder2[i]):\n",
    "                tickOrderedList[position].extend(vars)\n",
    "\n",
    "    \n",
    "    eod_results = (runProcesses(retrieve_eod_ohlc, OrderedList, 'imap'))\n",
    "    oi_results = (runProcesses(retrieve_openInterest, OrderedList, 'imap'))\n",
    "    tick_results = (runProcesses(generate_option_tick, tickOrderedList, 'imap'))\n",
    "    tick_results = list(set(tick_results))\n",
    "\n",
    "\n",
    "    ## Save to Dictionary Cache\n",
    "    for tick, eod, oi in zip(tick_results, eod_results, oi_results):\n",
    "        cache_key = f\"{tick}_{date}\"\n",
    "        close_cache[cache_key] = eod\n",
    "        oi_cache[cache_key] = oi\n",
    "\n",
    "\n",
    "    ## Test1: Run spot_cache process after close_cache has been populate.\n",
    "    \n",
    "    spot_results = list(runProcesses(return_closePrice, [tick_results, [date]*len(tick_results)], 'imap'))   \n",
    "    for tick, spot in zip(tick_results, spot_results):\n",
    "        cache_key = f\"{tick}_{date}\"\n",
    "        spot_cache[cache_key] = spot\n",
    "\n",
    "\n",
    "    ## Test2: We will edit the populate spot_cache populate function to make an api call instead of using the cache.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_order_candidates(settings, tick, date, right = 'P'):\n",
    "    order_candidates = {'long': [], 'short': []}\n",
    "    for spec in settings['specifics']:\n",
    "        order_candidates[spec['direction']].append(chain_details(date, tick, spec['dte'], spec['rel_strike'], right,  moneyness_width = spec['moneyness_width']))\n",
    "    return order_candidates\n",
    "\n",
    "\n",
    "def liquidity_check(id, date, pass_threshold = 250):\n",
    "    sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "    new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "    transfer_dict = {}\n",
    "    for k, v in sample_id.items():\n",
    "\n",
    "        if k in new_dict_keys:\n",
    "            if k == 'strike':\n",
    "                transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "            else:\n",
    "                transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "\n",
    "    start = (pd.to_datetime(date) - BDay(10)).strftime('%Y-%m-%d')\n",
    "    oi_data = retrieve_openInterest(**transfer_dict, end_date=date, start_date=start)\n",
    "    # print(f'Open Interest > {pass_threshold} for {id}:', oi_data.Open_interest.mean() )\n",
    "    return oi_data.Open_interest.mean() > pass_threshold\n",
    "\n",
    "\n",
    "def available_close_check(id, date, threshold = 0.7):\n",
    "    cache_key = f\"{id}_{date}\"\n",
    "    sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "    new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "    transfer_dict = {}\n",
    "    for k, v in sample_id.items():\n",
    "        if k in new_dict_keys:\n",
    "            if k == 'strike':\n",
    "                transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "            else:\n",
    "                transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "    \n",
    "    if cache_key in close_cache:\n",
    "        close_data_sample = close_cache[cache_key]\n",
    "    else:\n",
    "        start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "        close_data_sample = retrieve_eod_ohlc(**transfer_dict, start_date=start, end_date=date)\n",
    "        close_cache[cache_key] = close_data_sample\n",
    "    close_mask_series = close_data_sample.Close != 0\n",
    "    return close_mask_series.sum()/len(close_mask_series) > threshold\n",
    "\n",
    "\n",
    "def get_structure_price(tradeables, direction_index, date, tick, right = 'P'):\n",
    "    pack_price = {}\n",
    "    pack_dataframe = pd.DataFrame()\n",
    "    pack_dataframe['close'] = 0\n",
    "\n",
    "    for pack_i, pack in enumerate(tradeables):\n",
    "        pack_close = 0\n",
    "        for i, id in enumerate(pack):\n",
    "            if id not in spot_cache:\n",
    "                \n",
    "                cache_key = f\"{id}_{date}\"\n",
    "                sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "                new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "                transfer_dict = {}\n",
    "                for k, v in sample_id.items():\n",
    "                    if k in new_dict_keys:\n",
    "                        if k == 'strike':\n",
    "                            transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "                        else:\n",
    "                            transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "                start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "                close_data_sample = retrieve_eod_ohlc(**transfer_dict, start_date=start, end_date=date)\n",
    "                close_data_sample = close_data_sample[~close_data_sample.index.duplicated(keep = 'first')]\n",
    "                close = close_data_sample['Midpoint'][date]\n",
    "                spot_cache[cache_key] = close\n",
    "            else:\n",
    "                close = cache_key[id]\n",
    "            pack_close += close * direction_index[i]\n",
    "            pack_dataframe.at[pack_i, i] = id\n",
    "\n",
    "        pack_dataframe.at[pack_i, 'close'] = pack_close\n",
    "    return pack_dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_details(date, ticker, tgt_dte, tgt_moneyness, right = 'P', moneyness_width = 0.15, print_stderr = False):\n",
    "    return_dataframe = pd.DataFrame()\n",
    "    errors = {}\n",
    "    if not (is_USholiday(date) and not is_busday(date)):\n",
    "        try:\n",
    "            print(date, ticker) if print_stderr else None\n",
    "            ## Get both calls and puts per moneyness. For 1 Moneyness, both will most be available. If not, if one is False, other True. \n",
    "            ## We will need to get two rows. \n",
    "            chain_key = f\"{date}_{ticker}\"\n",
    "            with Context(end_date = date):\n",
    "                if chain_key in chain_cache:\n",
    "                    Option_Chain = chain_cache[chain_key]\n",
    "                else:\n",
    "                    start_time = time.time()\n",
    "                    Stock_obj = Stock(ticker, run_chain = False)\n",
    "                    end_time = time.time()\n",
    "                    print(f\"Time taken to get stock object: {end_time-start_time}\") if print_stderr else None\n",
    "                    Option_Chain = Stock_obj.option_chain()\n",
    "                    Spot = Stock_obj.spot(ts = False)\n",
    "                    Spot = list(Spot.values())[0]\n",
    "                    Option_Chain['Spot'] = Spot\n",
    "                    Option_Chain['q'] = Stock_obj.div_yield()\n",
    "                    Option_Chain['r'] = Stock_obj.rf_rate\n",
    "                    chain_cache[chain_key] = Option_Chain\n",
    "\n",
    "                \n",
    "                Option_Chain_Filtered = Option_Chain[Option_Chain[right.upper()] == True]\n",
    "                \n",
    "                \n",
    "                if right == 'P':\n",
    "                    Option_Chain_Filtered['relative_moneyness']  = Option_Chain_Filtered.index.get_level_values('strike')/Option_Chain_Filtered.Spot\n",
    "                elif right == 'C':\n",
    "                    Option_Chain_Filtered['relative_moneyness']  = Option_Chain_Filtered.Spot/Option_Chain_Filtered.index.get_level_values('strike')\n",
    "                else:\n",
    "                    raise ValueError(f'Right dne. recieved {right}')\n",
    "                Option_Chain_Filtered['moneyness_spread'] = (tgt_moneyness-Option_Chain_Filtered['relative_moneyness'])**2\n",
    "                Option_Chain_Filtered['dte_spread'] = (Option_Chain_Filtered.index.get_level_values('DTE')-tgt_dte)**2\n",
    "                Option_Chain_Filtered.sort_values(by=['dte_spread','moneyness_spread'], inplace = True)\n",
    "                Option_Chain_Filtered = Option_Chain_Filtered.loc[Option_Chain_Filtered['dte_spread'] == Option_Chain_Filtered['dte_spread'].min()]\n",
    "                if float(moneyness_width) == 0.0:\n",
    "                    option_details = Option_Chain_Filtered.sort_values('moneyness_spread', ascending=False).head(1)\n",
    "                else:\n",
    "                    option_details = Option_Chain_Filtered[(Option_Chain_Filtered['relative_moneyness'] >= tgt_moneyness-moneyness_width) & \n",
    "                                                        (Option_Chain_Filtered['relative_moneyness'] <= tgt_moneyness+moneyness_width)]\n",
    "                option_details['build_date'] = date\n",
    "                option_details['ticker'] = ticker\n",
    "                option_details['moneyness'] = tgt_moneyness\n",
    "                option_details['TGT_DTE'] = tgt_dte\n",
    "                option_details.reset_index(inplace = True)\n",
    "                option_details.set_index('build_date', inplace = True)\n",
    "                option_details['right'] = right\n",
    "                option_details.drop(columns = ['C','P'], inplace = True)\n",
    "                option_details['option_id'] = option_details.apply(lambda x: generate_option_tick(symbol = x['ticker'], \n",
    "                                                                    exp = x['expiration'].strftime('%Y-%m-%d'), strike = float(x['strike']), right = x['right']), axis = 1)\n",
    "                return_dataframe = pd.concat([return_dataframe, option_details])\n",
    "            clear_context()\n",
    "            return_dataframe.drop_duplicates(inplace = True)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise\n",
    "\n",
    "        return return_dataframe.sort_values('relative_moneyness', ascending=False)\n",
    "    else:\n",
    "        return None, errors\n",
    "    \n",
    "\n",
    "details= chain_details('2024-03-12', 'TSLA', 365, 0.7, moneyness_width = 0.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING ORDERPICKER AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['TSLA20250321000165C'],\n",
       " 'S': ['TSLA20250321000200C'],\n",
       " 'trade_id': '&L:TSLA20250321000165C&S:TSLA20250321000200C',\n",
       " 'close': 9.674999999999997}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class OrderPicker:\n",
    "    def __init__(self):\n",
    "        self.liquidity_threshold = 250\n",
    "        self.data_availability_threshold = 0.7\n",
    "        self.lookback = 30\n",
    "\n",
    "    def get_order(self, \n",
    "                  tick, \n",
    "                  date,\n",
    "                  right, \n",
    "                  max_close,\n",
    "                  order_settings):\n",
    "        \n",
    "        ## Create necessary data structures\n",
    "        direction_index = {}\n",
    "        str_direction_index = {}\n",
    "        for indx, v in enumerate(order_settings['specifics']):\n",
    "            if v['direction'] == 'long':\n",
    "                str_direction_index[indx] = 'L'\n",
    "                direction_index[indx] = 1\n",
    "            elif v['direction'] == 'short':\n",
    "                str_direction_index[indx] = 'S'\n",
    "                direction_index[indx] = -1\n",
    "\n",
    "\n",
    "        load_chain(date, 'TSLA')\n",
    "        order_candidates = produce_order_candidates(order_settings, tick, date, right)\n",
    "\n",
    "\n",
    "        populate_cache(order_candidates, date=date)\n",
    "\n",
    "\n",
    "        for direction in order_candidates:\n",
    "            for i,data in enumerate(order_candidates[direction]):\n",
    "                data['liquidity_check'] = data.option_id.apply(lambda x: liquidity_check(x, date))\n",
    "                data = data[data.liquidity_check == True]\n",
    "                data['available_close_check'] = data.option_id.apply(lambda x: available_close_check(x, date))\n",
    "                order_candidates[direction][i] = data[data.available_close_check == True] \n",
    "\n",
    "\n",
    "\n",
    "        ## Filter Unique Combinations per leg.\n",
    "        unique_ids = {'long': [], 'short': []}\n",
    "        for direction in order_candidates:\n",
    "            for i,data in enumerate(order_candidates[direction]):\n",
    "                unique_ids[direction].append(data[(data.liquidity_check == True) & (data.available_close_check == True)].option_id.unique().tolist())\n",
    "\n",
    "        ## Produce Tradeable Combinations\n",
    "        tradeable_ids = list(product(*unique_ids['long'], *unique_ids['short']))\n",
    "        tradeable_ids, unique_ids \n",
    "\n",
    "        ## Keep only unique combinations. Not repeating a contract.\n",
    "        filtered = [t for t in tradeable_ids if len(set(t)) == len(t)]\n",
    "\n",
    "        ## Get the price of the structure\n",
    "        ## Using List Comprehension to sum the prices of the structure per index\n",
    "        results = [\n",
    "            (*items, sum([direction_index[i] * spot_cache[f'{item}_{date}'] for i, item in enumerate(items)])) for items in filtered\n",
    "        ]\n",
    "\n",
    "        ## Convert to DataFrame, and sort by the price of the structure.\n",
    "        return_dataframe = pd.DataFrame(results)\n",
    "        cols = return_dataframe.columns.tolist()\n",
    "        cols[-1] = 'close'\n",
    "        return_dataframe.columns= cols\n",
    "        return_dataframe = return_dataframe[(return_dataframe.close<= max_close) & (return_dataframe.close> 0)].sort_values('close', ascending = False).head(1)\n",
    "\n",
    "        ## Rename the columns to the direction names\n",
    "        return_dataframe.columns = list(str_direction_index.values()) + ['close']\n",
    "        return_order = return_dataframe[list(str_direction_index.values())].to_dict(orient = 'list')\n",
    "        return_order\n",
    "\n",
    "        ## Create the trade_id with the direction and the id of the contract.\n",
    "        id = ''\n",
    "        for k, v in return_order.items():\n",
    "            id += f\"&{k}:{v[0]}\"\n",
    "\n",
    "        return_order['trade_id'] = id\n",
    "        return_order['close'] = return_dataframe.close.values[0]\n",
    "\n",
    "        return return_order\n",
    "\n",
    "\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.10},\n",
    "                {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.10} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }\n",
    "\n",
    "\n",
    "tick = 'TSLA'\n",
    "date = '2024-03-12'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'P'\n",
    "\n",
    "\n",
    "picker = OrderPicker()\n",
    "er = picker.get_order(tick, date, 'C', 10, order_settings)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['TSLA20250321000165C'],\n",
       " 'S': ['TSLA20250321000200C'],\n",
       " 'trade_id': '&L:TSLA20250321000165C&S:TSLA20250321000200C',\n",
       " 'close': 9.674999999999997}"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RiskManager:\n",
    "    def __init__(self,\n",
    "                 bars,\n",
    "                 events,\n",
    "                 initial_capital,\n",
    "                 ):\n",
    "        self.bars = bars\n",
    "        self.events = events\n",
    "        self.initial_capital = initial_capital\n",
    "        # self.symbol_list = self.bars.symbol_list\n",
    "        self.OrderPicker = OrderPicker()\n",
    "\n",
    "\n",
    "    def get_order(self, symbol, date, order_settings):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "rm = RiskManager(None, None, 1000000)\n",
    "rm.OrderPicker.get_order(tick, date, 'C', 10, order_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRY RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['BAC20240621000035C'],\n",
       " 'trade_id': '&L:BAC20240621000035C',\n",
       " 'close': 5.0}"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_close = 5\n",
    "\n",
    "direction_index = {}\n",
    "str_direction_index = {}\n",
    "for indx, v in enumerate(order_settings['specifics']):\n",
    "    if v['direction'] == 'long':\n",
    "        str_direction_index[indx] = 'L'\n",
    "        direction_index[indx] = 1\n",
    "    elif v['direction'] == 'short':\n",
    "        str_direction_index[indx] = 'S'\n",
    "        direction_index[indx] = -1\n",
    "\n",
    "\n",
    "load_chain(date, 'TSLA')\n",
    "order_candidates = produce_order_candidates(order_settings, tick, date, right)\n",
    "\n",
    "\n",
    "populate_cache(order_candidates, date=date)\n",
    "\n",
    "\n",
    "for direction in order_candidates:\n",
    "    for i,data in enumerate(order_candidates[direction]):\n",
    "        data['liquidity_check'] = data.option_id.apply(lambda x: liquidity_check(x, date))\n",
    "        data = data[data.liquidity_check == True]\n",
    "        data['available_close_check'] = data.option_id.apply(lambda x: available_close_check(x, date))\n",
    "        order_candidates[direction][i] = data[data.available_close_check == True] \n",
    "\n",
    "\n",
    "\n",
    "## Filter Unique Combinations per leg.\n",
    "unique_ids = {'long': [], 'short': []}\n",
    "for direction in order_candidates:\n",
    "    for i,data in enumerate(order_candidates[direction]):\n",
    "        unique_ids[direction].append(data[(data.liquidity_check == True) & (data.available_close_check == True)].option_id.unique().tolist())\n",
    "\n",
    "## Produce Tradeable Combinations\n",
    "tradeable_ids = list(product(*unique_ids['long'], *unique_ids['short']))\n",
    "tradeable_ids, unique_ids \n",
    "\n",
    "## Keep only unique combinations. Not repeating a contract.\n",
    "filtered = [t for t in tradeable_ids if len(set(t)) == len(t)]\n",
    "\n",
    "## Get the price of the structure\n",
    "## Using List Comprehension to sum the prices of the structure per index\n",
    "results = [\n",
    "    (*items, sum([direction_index[i] * spot_cache[f'{item}_{date}'] for i, item in enumerate(items)])) for items in filtered\n",
    "]\n",
    "\n",
    "## Convert to DataFrame, and sort by the price of the structure.\n",
    "return_dataframe = pd.DataFrame(results)\n",
    "cols = return_dataframe.columns.tolist()\n",
    "cols[-1] = 'close'\n",
    "return_dataframe.columns= cols\n",
    "return_dataframe = return_dataframe[(return_dataframe.close<= max_close) & (return_dataframe.close> 0)].sort_values('close', ascending = False).head(1)\n",
    "\n",
    "## Rename the columns to the direction names\n",
    "return_dataframe.columns = list(str_direction_index.values()) + ['close']\n",
    "return_order = return_dataframe[list(str_direction_index.values())].to_dict(orient = 'list')\n",
    "return_order\n",
    "\n",
    "## Create the trade_id with the direction and the id of the contract.\n",
    "id = ''\n",
    "for k, v in return_order.items():\n",
    "    id += f\"&{k}:{v[0]}\"\n",
    "\n",
    "return_order['trade_id'] = id\n",
    "return_order['close'] = return_dataframe.close.values[0]\n",
    "\n",
    "return_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task: https://api.github.com\n",
      "Starting task: https://api.spacexdata.com/v4/launches/latest\n",
      "Starting task: https://jsonplaceholder.typicode.com/todos/1\n",
      "Completed task: https://api.github.com\n",
      "Completed task: https://api.spacexdata.com/v4/launches/latest\n",
      "Completed task: https://jsonplaceholder.typicode.com/todos/1\n",
      "{'current_user_url': 'https://api.github.com/user', 'current_user_authorizations_html_url': 'https://github.com/settings/connections/applications{/client_id}', 'authorizations_url': 'https://api.github.com/authorizations', 'code_search_url': 'https://api.github.com/search/code?q={query}{&page,per_page,sort,order}', 'commit_search_url': 'https://api.github.com/search/commits?q={query}{&page,per_page,sort,order}', 'emails_url': 'https://api.github.com/user/emails', 'emojis_url': 'https://api.github.com/emojis', 'events_url': 'https://api.github.com/events', 'feeds_url': 'https://api.github.com/feeds', 'followers_url': 'https://api.github.com/user/followers', 'following_url': 'https://api.github.com/user/following{/target}', 'gists_url': 'https://api.github.com/gists{/gist_id}', 'hub_url': 'https://api.github.com/hub', 'issue_search_url': 'https://api.github.com/search/issues?q={query}{&page,per_page,sort,order}', 'issues_url': 'https://api.github.com/issues', 'keys_url': 'https://api.github.com/user/keys', 'label_search_url': 'https://api.github.com/search/labels?q={query}&repository_id={repository_id}{&page,per_page}', 'notifications_url': 'https://api.github.com/notifications', 'organization_url': 'https://api.github.com/orgs/{org}', 'organization_repositories_url': 'https://api.github.com/orgs/{org}/repos{?type,page,per_page,sort}', 'organization_teams_url': 'https://api.github.com/orgs/{org}/teams', 'public_gists_url': 'https://api.github.com/gists/public', 'rate_limit_url': 'https://api.github.com/rate_limit', 'repository_url': 'https://api.github.com/repos/{owner}/{repo}', 'repository_search_url': 'https://api.github.com/search/repositories?q={query}{&page,per_page,sort,order}', 'current_user_repositories_url': 'https://api.github.com/user/repos{?type,page,per_page,sort}', 'starred_url': 'https://api.github.com/user/starred{/owner}{/repo}', 'starred_gists_url': 'https://api.github.com/gists/starred', 'topic_search_url': 'https://api.github.com/search/topics?q={query}{&page,per_page}', 'user_url': 'https://api.github.com/users/{user}', 'user_organizations_url': 'https://api.github.com/user/orgs', 'user_repositories_url': 'https://api.github.com/users/{user}/repos{?type,page,per_page,sort}', 'user_search_url': 'https://api.github.com/search/users?q={query}{&page,per_page,sort,order}'}\n",
      "{'fairings': None, 'links': {'patch': {'small': 'https://images2.imgbox.com/eb/d8/D1Yywp0w_o.png', 'large': 'https://images2.imgbox.com/33/2e/k6VE4iYl_o.png'}, 'reddit': {'campaign': None, 'launch': 'https://www.reddit.com/r/spacex/comments/xvm76j/rspacex_crew5_launchcoast_docking_discussion_and/', 'media': None, 'recovery': None}, 'flickr': {'small': [], 'original': []}, 'presskit': None, 'webcast': 'https://youtu.be/5EwW8ZkArL4', 'youtube_id': '5EwW8ZkArL4', 'article': None, 'wikipedia': 'https://en.wikipedia.org/wiki/SpaceX_Crew-5'}, 'static_fire_date_utc': None, 'static_fire_date_unix': None, 'net': False, 'window': None, 'rocket': '5e9d0d95eda69973a809d1ec', 'success': True, 'failures': [], 'details': None, 'crew': ['62dd7196202306255024d13c', '62dd71c9202306255024d13d', '62dd7210202306255024d13e', '62dd7253202306255024d13f'], 'ships': [], 'capsules': ['617c05591bad2c661a6e2909'], 'payloads': ['62dd73ed202306255024d145'], 'launchpad': '5e9e4502f509094188566f88', 'flight_number': 187, 'name': 'Crew-5', 'date_utc': '2022-10-05T16:00:00.000Z', 'date_unix': 1664985600, 'date_local': '2022-10-05T12:00:00-04:00', 'date_precision': 'hour', 'upcoming': False, 'cores': [{'core': '633d9da635a71d1d9c66797b', 'flight': 1, 'gridfins': True, 'legs': True, 'reused': False, 'landing_attempt': True, 'landing_success': True, 'landing_type': 'ASDS', 'landpad': '5e9e3033383ecbb9e534e7cc'}], 'auto_update': True, 'tbd': False, 'launch_library_id': 'f33d5ece-e825-4cd8-809f-1d4c72a2e0d3', 'id': '62dd70d5202306255024d139'}\n",
      "{'userId': 1, 'id': 1, 'title': 'delectus aut autem', 'completed': False}\n",
      "Total time taken: 0.1384739875793457 seconds\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def fetch_data(session, url):\n",
    "    print(f\"Starting task: {url}\")\n",
    "    async with session.get(url) as response:\n",
    "        data = await response.json()\n",
    "        print(f\"Completed task: {url}\")\n",
    "        return data\n",
    "\n",
    "async def main():\n",
    "    urls = [\n",
    "        'https://api.github.com',\n",
    "        'https://api.spacexdata.com/v4/launches/latest',\n",
    "        'https://jsonplaceholder.typicode.com/todos/1'\n",
    "    ]\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_data(session, url) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for result in results:\n",
    "            print(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    asyncio.run(main())\n",
    "    print(f\"Total time taken: {time.time() - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to producing an order:\n",
    "\n",
    "- S1: RM recieves order settings from PM\n",
    "- S2: RM produces a dataframe of potential options based on settings (if two legs produce two dataframes)\n",
    "- S3: RM assesses if option passes all checks\n",
    "    - C1: Minimum Available close\n",
    "    - C2: Liquidity (Open Interest)\n",
    "    - C2.5: (for Spreads only) Ensure both legs are not the same\n",
    "    - Optional, to extend:\n",
    "    - C3: Bid-Ask Spread\n",
    "    \n",
    "- S4: Return picked order to portfolio manager, which places the order. \n",
    "- Example:\n",
    "    {'long': [optionid or {'strike', 'exp'}], 'short' : []}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openbb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
