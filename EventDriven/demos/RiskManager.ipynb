{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from EventDriven.riskmanager import RiskManager, LOOKBACKS, close_cache, chain_cache, oi_cache, spot_cache\n",
    "from dbase.DataAPI.ThetaData import list_contracts\n",
    "from trade.assets.Calculate import Calculate\n",
    "from trade.helpers.helper import parse_option_tick\n",
    "from trade.assets.rates\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': [{'ticker': 'AAPL',\n",
       "   'put_call': 'C',\n",
       "   'exp_date': '2024-01-19',\n",
       "   'strike': 210.0}],\n",
       " 'S': [{'ticker': 'AAPL',\n",
       "   'put_call': 'C',\n",
       "   'exp_date': '2024-01-19',\n",
       "   'strike': 245.0}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_str = '&L:AAPL20240119C210&S:AAPL20240119C245'\n",
    "position_list = position_str.split('&')\n",
    "position_list = [x.split(':') for x in position_list if x]\n",
    "position_list = [(x[0], parse_option_tick(x[1])) for x in position_list]\n",
    "position_dict = dict(L = [], S = [])\n",
    "for x in position_list:\n",
    "    position_dict[x[0]].append(x[1])\n",
    "position_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mCalculate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreeks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0masset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Returns all the greeks of an option as dictionary\n",
      "\u001b[0;31mFile:\u001b[0m      ~/cloned_repos/QuantTools/trade/assets/Calculate.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "Calculate.greeks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'BA', '2023-08-03', 'C', 5, {'type': 'naked', 'specifics': [{'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.1}], 'name': 'naked_call'\n",
    "'SBUX', '2023-11-08', 'C', 5, {'type': 'naked', 'specifics': [{'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.1}], 'name': 'naked_call'})\n",
    "'LLY', '2023-07-05', 'C', 15, {'type': 'naked', 'specifics': [{'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.1}], 'name': 'naked_call'}), {}\n",
    "'MU', '2023-11-10', 'C', 15, {'type': 'naked', 'specifics': [{'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.1}], 'name': 'naked_call'}), {}\n",
    "'LLY', '2023-07-05', 'C', 10, {'type': 'naked', 'specifics': [{'direction': 'long', 'rel_strike': 0.75, 'dte': 365, 'moneyness_width': 0.1}], 'name': 'naked_call'}), {}\n",
    " 'BAC', '2022-11-12', 'C', 4.1472, {'type': 'naked', 'specifics': [{'direction': 'long', 'rel_strike': 0.85, 'dte': 300, 'moneyness_width': 0.35}, {'direction': 'short', 'rel_strike': 0.6, 'dte': 300, 'moneyness_width': 0.35}], 'name': 'vertical_spread'}), {}\n",
    "'TSLA', '2023-06-02', 'C', 2, {'type': 'naked', 'specifics': [{'direction': 'long', 'rel_strike': 0.85, 'dte': 300, 'moneyness_width': 0.35}, {'direction': 'short', 'rel_strike': 0.6, 'dte': 300, 'moneyness_width': 0.35}], 'name': 'vertical_spread'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = RiskManager(None, None, None)\n",
    "rm.OrderPicker.liquidity_threshold = 100\n",
    "rm.OrderPicker.lookback = 10\n",
    "order = rm.OrderPicker.get_order('TSLA', '2023-06-02', 'C', 2, \n",
    "                                  {'type': 'naked', 'specifics': [{'direction': 'long', 'rel_strike': 0.85, 'dte': 300, 'moneyness_width': 0.35}, {'direction': 'short', 'rel_strike': 0.6, 'dte': 300, 'moneyness_width': 0.35}], 'name': 'vertical_spread'})\n",
    "\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderPicker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtick\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mright\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_close\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0morder_settings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "returns the order for the given tick, date, right, max_close, and order_settings\n",
      "\n",
      "params:\n",
      "tick: str: ticker to get the order for\n",
      "date: str: date to get the order for\n",
      "right: str: right of the option contract (P or C)\n",
      "max_close: str: maximum close price\n",
      "order_settings: dict: settings for the order\n",
      "    example: {'type': 'naked',\n",
      "                'specifics': [{'direction': 'long',\n",
      "                'rel_strike': .900,\n",
      "                'dte': 365,\n",
      "                'moneyness_width': 0.15},\n",
      "                {'direction': 'short',\n",
      "                'rel_strike': .80,\n",
      "                'dte': 365,\n",
      "                'moneyness_width': 0.15}],\n",
      "\n",
      "                'name': 'vertical_spread'}\n",
      "\n",
      "returns:\n",
      "dict: order\n",
      "\u001b[0;31mFile:\u001b[0m      ~/cloned_repos/QuantTools/EventDriven/riskmanager.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "rm.OrderPicker.get_order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Console Logging & File Logging Can be configured using STREAM_LOG_LEVEL and FILE_LOG_LEVEL in environment variables.\n",
      "Propagate to root logger can be set using PROPAGATE_TO_ROOT_LOGGER in environment variables.\n",
      "Example:\n",
      "STREAM_LOG_LEVEL = 'DEBUG'\n",
      "FILE_LOG_LEVEL = 'INFO'\n",
      "PROPAGATE_TO_ROOT_LOGGER = 'False'\n",
      "\n",
      "Using Proxy URL: http://18.232.166.224:5500/thetadata\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "os.environ['STREAM_LOG_LEVEL'] = 'ERROR'\n",
    "os.environ['FILE_LOG_LEVEL'] = 'DEBUG'\n",
    "os.environ['PROPAGATE_TO_ROOT_LOGGER'] = 'False'\n",
    "os.environ['PROPAGATE_TO_ROOT_LOGGER'], os.environ['STREAM_LOG_LEVEL']\n",
    "from trade.assets.Stock import Stock\n",
    "from trade.assets.Option import Option\n",
    "from trade.assets.OptionStructure import OptionStructure\n",
    "from trade.helpers.Context import Context, clear_context\n",
    "from trade.helpers.helper import (change_to_last_busday, \n",
    "                                  is_USholiday, \n",
    "                                  is_busday, \n",
    "                                  setup_logger, \n",
    "                                  generate_option_tick, \n",
    "                                  get_option_specifics_from_key,\n",
    "                                  identify_length,\n",
    "                                  extract_numeric_value)\n",
    "from scipy.stats import percentileofscore\n",
    "from EventDriven.riskmanager import RiskManager\n",
    "from dbase.DataAPI.ThetaData import (list_contracts, retrieve_openInterest, retrieve_eod_ohlc, retrieve_quote)\n",
    "from pandas.tseries.offsets import BDay\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from trade.helpers.types import ResultsEnum\n",
    "from copy import deepcopy\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import numpy as np\n",
    "import time\n",
    "chain_cache = {}\n",
    "close_cache = {}\n",
    "oi_cache = {}\n",
    "spot_cache = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['AAPL20250620000235C'],\n",
       " 'S': ['AAPL20250620000260C'],\n",
       " 'trade_id': '&L:AAPL20250620000235C&S:AAPL20250620000260C',\n",
       " 'close': 4.925000000000001}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EventDriven.riskmanager import RiskManager, spot_cache, oi_cache, close_cache, chain_cache\n",
    "from pandas.tseries.offsets import BDay\n",
    "import pandas as pd\n",
    "\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.15},\n",
    "                {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.15} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }\n",
    "tick = 'AAPL'\n",
    "date = '2024-07-24'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'C'\n",
    "\n",
    "rm = RiskManager(None, None, 1000000)\n",
    "rm.OrderPicker.get_order(tick, date, 'C', 5, order_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLE ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = 'BAC'\n",
    "date = '2023-07-24'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'C'\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.15},\n",
    "                # {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.15} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTIPROCESSING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from abc import ABC, abstractmethod\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from pathos.multiprocessing import cpu_count\n",
    "from pathos.pools import _ProcessPool\n",
    "from threading import Thread\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "shutdown_event = False\n",
    "\n",
    "def runProcesses(func, OrderedInputs: List[List], run_type: str = 'map') -> List:\n",
    "    global shutdown_event\n",
    "    try:\n",
    "\n",
    "        pool = Pool(20)\n",
    "        pool.restart()\n",
    "        if run_type == 'map':\n",
    "            results = pool.map(func, *OrderedInputs)\n",
    "        elif run_type == 'amap':\n",
    "            results = pool.amap(func, *OrderedInputs)\n",
    "        elif run_type == 'uimap':\n",
    "            results = pool.uimap(func, *OrderedInputs)\n",
    "        elif run_type == 'imap':\n",
    "            results = pool.imap(func, *OrderedInputs)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'Run type {run_type} not recognized')\n",
    "\n",
    "    except KeyboardInterrupt as e:\n",
    "\n",
    "        shutdown_event = True\n",
    "        shutdown(pool)\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error occured: ', e)\n",
    "        shutdown(pool)\n",
    "\n",
    "\n",
    "    finally:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def shutdown(pool):\n",
    "    global shutdown_event\n",
    "    shutdown_event\n",
    "    shutdown_event = True\n",
    "    pool.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELEVANT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_closePrice(id, date):\n",
    "    global close_cache, spot_cache\n",
    "    cache_key = f\"{id}_{date}\"\n",
    "    close_data = close_cache[cache_key]\n",
    "    close_data = close_data[~close_data.index.duplicated(keep = 'first')]\n",
    "    close = close_data['Midpoint'][date]\n",
    "    return close\n",
    "\n",
    "\n",
    "def load_chain(date, ticker,  print_stderr = False):\n",
    "        print(date, ticker) if print_stderr else None\n",
    "        ## Get both calls and puts per moneyness. For 1 Moneyness, both will most be available. If not, if one is False, other True. \n",
    "        ## We will need to get two rows. \n",
    "        chain_key = f\"{date}_{ticker}\"\n",
    "        with Context(end_date = date):\n",
    "            if chain_key in chain_cache:\n",
    "                Option_Chain = chain_cache[chain_key]\n",
    "            else:\n",
    "                start_time = time.time()\n",
    "                Stock_obj = Stock(ticker, run_chain = False)\n",
    "                end_time = time.time()\n",
    "                print(f\"Time taken to get stock object: {end_time-start_time}\") if print_stderr else None\n",
    "                Option_Chain = Stock_obj.option_chain()\n",
    "                Spot = Stock_obj.spot(ts = False)\n",
    "                Spot = list(Spot.values())[0]\n",
    "                Option_Chain['Spot'] = Spot\n",
    "                Option_Chain['q'] = Stock_obj.div_yield()\n",
    "                Option_Chain['r'] = Stock_obj.rf_rate\n",
    "                chain_cache[chain_key] = Option_Chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_cache(order_candidates, date = '2024-03-12',):\n",
    "\n",
    "    global close_cache, oi_cache, spot_cache\n",
    "\n",
    "    tempholder1 = {}\n",
    "    tempholder2 = {}\n",
    "\n",
    "    ## Create necessary data structures\n",
    "    ## Looping through the order candidates to get the necessary data, and organize into a list of lists that will be passed to runProcesses function\n",
    "    for j, direction in enumerate(order_candidates):\n",
    "        for i,data in enumerate(order_candidates[direction]):\n",
    "            data[[ 'exp', 'strike', 'symbol']] = data[[ 'expiration', 'strike', 'ticker']]\n",
    "            start = (pd.to_datetime(date) - BDay(20)).strftime('%Y-%m-%d')\n",
    "            data[['end_date', 'start_date']] = date, start\n",
    "            data['exp'] = data['exp'].dt.strftime('%Y-%m-%d')\n",
    "            tempholder1[i+j] = (data[['symbol', 'end_date', 'exp', 'right', 'start_date', 'strike']].T.values.tolist())\n",
    "            tempholder2[i+j] = data[['symbol', 'right', 'exp','strike']].T.values.tolist()\n",
    "\n",
    "    ## Extending lists, to ensure only one runProcesses call is made, instead of run per side\n",
    "    for i, data in tempholder1.items():\n",
    "        if i == 0:\n",
    "            OrderedList = data\n",
    "            tickOrderedList = tempholder2[i]\n",
    "        else:\n",
    "            for position, vars in enumerate(data):\n",
    "                OrderedList[position].extend(vars)\n",
    "            for position, vars in enumerate(tempholder2[i]):\n",
    "                tickOrderedList[position].extend(vars)\n",
    "\n",
    "    \n",
    "    eod_results = (runProcesses(retrieve_eod_ohlc, OrderedList, 'imap'))\n",
    "    oi_results = (runProcesses(retrieve_openInterest, OrderedList, 'imap'))\n",
    "    tick_results = (runProcesses(generate_option_tick, tickOrderedList, 'imap'))\n",
    "    tick_results = list(set(tick_results))\n",
    "\n",
    "\n",
    "    ## Save to Dictionary Cache\n",
    "    for tick, eod, oi in zip(tick_results, eod_results, oi_results):\n",
    "        cache_key = f\"{tick}_{date}\"\n",
    "        close_cache[cache_key] = eod\n",
    "        oi_cache[cache_key] = oi\n",
    "\n",
    "\n",
    "    ## Test1: Run spot_cache process after close_cache has been populate.\n",
    "    \n",
    "    spot_results = list(runProcesses(return_closePrice, [tick_results, [date]*len(tick_results)], 'imap'))   \n",
    "    for tick, spot in zip(tick_results, spot_results):\n",
    "        cache_key = f\"{tick}_{date}\"\n",
    "        spot_cache[cache_key] = spot\n",
    "\n",
    "\n",
    "    ## Test2: We will edit the populate spot_cache populate function to make an api call instead of using the cache.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_order_candidates(settings, tick, date, right = 'P'):\n",
    "    order_candidates = {'long': [], 'short': []}\n",
    "    for spec in settings['specifics']:\n",
    "        chain = chain_details(date, tick, spec['dte'], spec['rel_strike'], right,  moneyness_width = spec['moneyness_width'])\n",
    "        order_candidates[spec['direction']].append(chain)\n",
    "    return order_candidates\n",
    "\n",
    "\n",
    "def liquidity_check(id, date, pass_threshold = 250):\n",
    "    sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "    new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "    transfer_dict = {}\n",
    "    for k, v in sample_id.items():\n",
    "\n",
    "        if k in new_dict_keys:\n",
    "            if k == 'strike':\n",
    "                transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "            else:\n",
    "                transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "\n",
    "    start = (pd.to_datetime(date) - BDay(10)).strftime('%Y-%m-%d')\n",
    "    oi_data = retrieve_openInterest(**transfer_dict, end_date=date, start_date=start)\n",
    "    # print(f'Open Interest > {pass_threshold} for {id}:', oi_data.Open_interest.mean() )\n",
    "    return oi_data.Open_interest.mean() > pass_threshold\n",
    "\n",
    "\n",
    "def available_close_check(id, date, threshold = 0.7):\n",
    "    cache_key = f\"{id}_{date}\"\n",
    "    sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "    new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "    transfer_dict = {}\n",
    "    for k, v in sample_id.items():\n",
    "        if k in new_dict_keys:\n",
    "            if k == 'strike':\n",
    "                transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "            else:\n",
    "                transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "    \n",
    "    if cache_key in close_cache:\n",
    "        close_data_sample = close_cache[cache_key]\n",
    "    else:\n",
    "        start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "        close_data_sample = retrieve_eod_ohlc(**transfer_dict, start_date=start, end_date=date)\n",
    "        close_cache[cache_key] = close_data_sample\n",
    "    close_mask_series = close_data_sample.Close != 0\n",
    "    return close_mask_series.sum()/len(close_mask_series) > threshold\n",
    "\n",
    "\n",
    "def get_structure_price(tradeables, direction_index, date, tick, right = 'P'):\n",
    "    pack_price = {}\n",
    "    pack_dataframe = pd.DataFrame()\n",
    "    pack_dataframe['close'] = 0\n",
    "\n",
    "    for pack_i, pack in enumerate(tradeables):\n",
    "        pack_close = 0\n",
    "        for i, id in enumerate(pack):\n",
    "            if id not in spot_cache:\n",
    "                \n",
    "                cache_key = f\"{id}_{date}\"\n",
    "                sample_id = deepcopy(get_option_specifics_from_key(id))\n",
    "                new_dict_keys = {'ticker': 'symbol', 'exp_date': 'exp', 'strike': 'strike', 'put_call': 'right'}\n",
    "                transfer_dict = {}\n",
    "                for k, v in sample_id.items():\n",
    "                    if k in new_dict_keys:\n",
    "                        if k == 'strike':\n",
    "                            transfer_dict[new_dict_keys[k]] = float(sample_id[k])\n",
    "                        else:\n",
    "                            transfer_dict[new_dict_keys[k]] = sample_id[k]\n",
    "                start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "                close_data_sample = retrieve_eod_ohlc(**transfer_dict, start_date=start, end_date=date)\n",
    "                close_data_sample = close_data_sample[~close_data_sample.index.duplicated(keep = 'first')]\n",
    "                close = close_data_sample['Midpoint'][date]\n",
    "                spot_cache[cache_key] = close\n",
    "            else:\n",
    "                close = cache_key[id]\n",
    "            pack_close += close * direction_index[i]\n",
    "            pack_dataframe.at[pack_i, i] = id\n",
    "\n",
    "        pack_dataframe.at[pack_i, 'close'] = pack_close\n",
    "    return pack_dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_details(date, ticker, tgt_dte, tgt_moneyness, right = 'P', moneyness_width = 0.15, print_stderr = False):\n",
    "    return_dataframe = pd.DataFrame()\n",
    "    errors = {}\n",
    "    if not (is_USholiday(date) and not is_busday(date)):\n",
    "        try:\n",
    "            print(date, ticker) if print_stderr else None\n",
    "            ## Get both calls and puts per moneyness. For 1 Moneyness, both will most be available. If not, if one is False, other True. \n",
    "            ## We will need to get two rows. \n",
    "            chain_key = f\"{date}_{ticker}\"\n",
    "            with Context(end_date = date):\n",
    "                if chain_key in chain_cache:\n",
    "                    Option_Chain = chain_cache[chain_key]\n",
    "                else:\n",
    "                    start_time = time.time()\n",
    "                    Stock_obj = Stock(ticker, run_chain = False)\n",
    "                    end_time = time.time()\n",
    "                    print(f\"Time taken to get stock object: {end_time-start_time}\") if print_stderr else None\n",
    "                    Option_Chain = Stock_obj.option_chain()\n",
    "                    Spot = Stock_obj.spot(ts = False)\n",
    "                    Spot = list(Spot.values())[0]\n",
    "                    Option_Chain['Spot'] = Spot\n",
    "                    Option_Chain['q'] = Stock_obj.div_yield()\n",
    "                    Option_Chain['r'] = Stock_obj.rf_rate\n",
    "                    chain_cache[chain_key] = Option_Chain\n",
    "\n",
    "                \n",
    "                Option_Chain_Filtered = Option_Chain[Option_Chain[right.upper()] == True]\n",
    "                \n",
    "                \n",
    "                if right == 'P':\n",
    "                    Option_Chain_Filtered['relative_moneyness']  = Option_Chain_Filtered.index.get_level_values('strike')/Option_Chain_Filtered.Spot\n",
    "                elif right == 'C':\n",
    "                    Option_Chain_Filtered['relative_moneyness']  = Option_Chain_Filtered.Spot/Option_Chain_Filtered.index.get_level_values('strike')\n",
    "                else:\n",
    "                    raise ValueError(f'Right dne. recieved {right}')\n",
    "                Option_Chain_Filtered['moneyness_spread'] = (tgt_moneyness-Option_Chain_Filtered['relative_moneyness'])**2\n",
    "                Option_Chain_Filtered['dte_spread'] = (Option_Chain_Filtered.index.get_level_values('DTE')-tgt_dte)**2\n",
    "                Option_Chain_Filtered.sort_values(by=['dte_spread','moneyness_spread'], inplace = True)\n",
    "                Option_Chain_Filtered = Option_Chain_Filtered.loc[Option_Chain_Filtered['dte_spread'] == Option_Chain_Filtered['dte_spread'].min()]\n",
    "                if float(moneyness_width) == 0.0:\n",
    "                    option_details = Option_Chain_Filtered.sort_values('moneyness_spread', ascending=False).head(1)\n",
    "                else:\n",
    "                    option_details = Option_Chain_Filtered[(Option_Chain_Filtered['relative_moneyness'] >= tgt_moneyness-moneyness_width) & \n",
    "                                                        (Option_Chain_Filtered['relative_moneyness'] <= tgt_moneyness+moneyness_width)]\n",
    "                \n",
    "                if option_details.empty:\n",
    "                    return None\n",
    "                \n",
    "                option_details['build_date'] = date\n",
    "                option_details['ticker'] = ticker\n",
    "                option_details['moneyness'] = tgt_moneyness\n",
    "                option_details['TGT_DTE'] = tgt_dte\n",
    "                option_details.reset_index(inplace = True)\n",
    "                option_details.set_index('build_date', inplace = True)\n",
    "                option_details['right'] = right\n",
    "                option_details.drop(columns = ['C','P'], inplace = True)\n",
    "                option_details['option_id'] = option_details.apply(lambda x: generate_option_tick(symbol = x['ticker'], \n",
    "                                                                    exp = x['expiration'].strftime('%Y-%m-%d'), strike = float(x['strike']), right = x['right']), axis = 1)\n",
    "                return_dataframe = pd.concat([return_dataframe, option_details])\n",
    "            clear_context()\n",
    "            return_dataframe.drop_duplicates(inplace = True)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise\n",
    "\n",
    "        return return_dataframe.sort_values('relative_moneyness', ascending=False)\n",
    "    else:\n",
    "        return None, errors\n",
    "    \n",
    "\n",
    "# details= chain_details('2024-03-12', 'TSLA', 365, 0.7, moneyness_width = 0.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING ORDERPICKER AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'SUCCESSFUL',\n",
       " 'data': {'long': ['TSLA20250620000215C'],\n",
       "  'short': ['TSLA20250620000235C'],\n",
       "  'trade_id': '&L:TSLA20250620000215C&S:TSLA20250620000235C',\n",
       "  'close': 9.674999999999997}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OrderPicker:\n",
    "    def __init__(self):\n",
    "        self.liquidity_threshold = 250\n",
    "        self.data_availability_threshold = 0.7\n",
    "        self.lookback = 30\n",
    "\n",
    "    def get_order(self, \n",
    "                  tick, \n",
    "                  date,\n",
    "                  right, \n",
    "                  max_close,\n",
    "                  order_settings):\n",
    "        \n",
    "        ## Create necessary data structures\n",
    "        direction_index = {}\n",
    "        str_direction_index = {}\n",
    "        for indx, v in enumerate(order_settings['specifics']):\n",
    "            if v['direction'] == 'long':\n",
    "                str_direction_index[indx] = 'long'\n",
    "                direction_index[indx] = 1\n",
    "            elif v['direction'] == 'short':\n",
    "                str_direction_index[indx] = 'short'\n",
    "                direction_index[indx] = -1\n",
    "\n",
    "\n",
    "        load_chain(date, 'TSLA')\n",
    "        order_candidates = produce_order_candidates(order_settings, tick, date, right)\n",
    "\n",
    "        if any([x2 is None for x in order_candidates.values() for x2 in x]):\n",
    "            return {\n",
    "                'result': ResultsEnum.MONEYNESS_TOO_TIGHT.value,\n",
    "                'data': None\n",
    "            } \n",
    "\n",
    "\n",
    "        populate_cache(order_candidates, date=date)\n",
    "\n",
    "\n",
    "        for direction in order_candidates:\n",
    "            for i,data in enumerate(order_candidates[direction]):\n",
    "                data['liquidity_check'] = data.option_id.apply(lambda x: liquidity_check(x, date))\n",
    "                data = data[data.liquidity_check == True]\n",
    "                data['available_close_check'] = data.option_id.apply(lambda x: available_close_check(x, date))\n",
    "                order_candidates[direction][i] = data[data.available_close_check == True] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## Filter Unique Combinations per leg.\n",
    "        unique_ids = {'long': [], 'short': []}\n",
    "        for direction in order_candidates:\n",
    "            for i,data in enumerate(order_candidates[direction]):\n",
    "                unique_ids[direction].append(data[(data.liquidity_check == True) & (data.available_close_check == True)].option_id.unique().tolist())\n",
    "\n",
    "        ## Produce Tradeable Combinations\n",
    "        tradeable_ids = list(product(*unique_ids['long'], *unique_ids['short']))\n",
    "        tradeable_ids, unique_ids \n",
    "\n",
    "        ## Keep only unique combinations. Not repeating a contract.\n",
    "        filtered = [t for t in tradeable_ids if len(set(t)) == len(t)]\n",
    "\n",
    "        ## Get the price of the structure\n",
    "        ## Using List Comprehension to sum the prices of the structure per index\n",
    "        results = [\n",
    "            (*items, sum([direction_index[i] * spot_cache[f'{item}_{date}'] for i, item in enumerate(items)])) for items in filtered\n",
    "        ]\n",
    "\n",
    "        ## Convert to DataFrame, and sort by the price of the structure.\n",
    "        return_dataframe = pd.DataFrame(results)\n",
    "        cols = return_dataframe.columns.tolist()\n",
    "        cols[-1] = 'close'\n",
    "        return_dataframe.columns= cols\n",
    "        return_dataframe = return_dataframe[(return_dataframe.close<= max_close) & (return_dataframe.close> 0)].sort_values('close', ascending = False).head(1)\n",
    "\n",
    "\n",
    "        if return_dataframe.empty:\n",
    "            return {\n",
    "                'result': ResultsEnum.MONEYNESS_TOO_TIGHT.value,\n",
    "                'data': None\n",
    "            } \n",
    "            \n",
    "        ## Rename the columns to the direction names\n",
    "        return_dataframe.columns = list(str_direction_index.values()) + ['close']\n",
    "        return_order = return_dataframe[list(str_direction_index.values())].to_dict(orient = 'list')\n",
    "        return_order\n",
    "\n",
    "        ## Create the trade_id with the direction and the id of the contract.\n",
    "        id = ''\n",
    "        for k, v in return_order.items():\n",
    "            id += f\"&{k[0].upper()}:{v[0]}\"\n",
    "\n",
    "        return_order['trade_id'] = id\n",
    "        return_order['close'] = return_dataframe.close.values[0]\n",
    "        return_dict = {\n",
    "            'result': ResultsEnum.SUCCESSFUL.value,\n",
    "            'data': return_order\n",
    "        }\n",
    "\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.10},\n",
    "                {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.10} \n",
    "            ],\n",
    "            'name': 'vertical_spread',\n",
    "        }\n",
    "\n",
    "\n",
    "tick = 'TSLA'\n",
    "date = '2024-07-24'\n",
    "start = (pd.to_datetime(date) - BDay(30)).strftime('%Y-%m-%d')\n",
    "right = 'P'\n",
    "\n",
    "\n",
    "picker = OrderPicker()\n",
    "er = picker.get_order(tick, date, 'C', 10, order_settings)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import set_start_method\n",
    "set_start_method(\"fork\", force = True)\n",
    "from trade.helpers.pools import runProcesses\n",
    "\n",
    "def test_func(x):\n",
    "    return x**2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    results = runProcesses(test_func, [[1,2,3,4,5]], 'imap')\n",
    "list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': ['TSLA20250321000165C'],\n",
       " 'S': ['TSLA20250321000200C'],\n",
       " 'trade_id': '&L:TSLA20250321000165C&S:TSLA20250321000200C',\n",
       " 'close': 9.674999999999997}"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RiskManager:\n",
    "    def __init__(self,\n",
    "                 bars,\n",
    "                 events,\n",
    "                 initial_capital,\n",
    "                 ):\n",
    "        self.bars = bars\n",
    "        self.events = events\n",
    "        self.initial_capital = initial_capital\n",
    "        # self.symbol_list = self.bars.symbol_list\n",
    "        self.OrderPicker = OrderPicker()\n",
    "\n",
    "\n",
    "    def get_order(self, symbol, date, order_settings):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "rm = RiskManager(None, None, 1000000)\n",
    "rm.OrderPicker.get_order(tick, date, 'C', 10, order_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRY RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m load_chain(date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSLA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m order_candidates \u001b[38;5;241m=\u001b[39m produce_order_candidates(order_settings, tick, date, right)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mpopulate_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m direction \u001b[38;5;129;01min\u001b[39;00m order_candidates:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(order_candidates[direction]):\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mpopulate_cache\u001b[0;34m(order_candidates, date)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, direction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(order_candidates):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(order_candidates[direction]):\n\u001b[0;32m---> 12\u001b[0m         data[[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrike\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpiration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstrike\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mticker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m         start \u001b[38;5;241m=\u001b[39m (pd\u001b[38;5;241m.\u001b[39mto_datetime(date) \u001b[38;5;241m-\u001b[39m BDay(\u001b[38;5;241m20\u001b[39m))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m         data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m date, start\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "max_close = 5\n",
    "\n",
    "\n",
    "order_settings = {\n",
    "            'type': 'spread',\n",
    "            'specifics': [\n",
    "                {'direction': 'long', 'rel_strike': 1.0, 'dte': 365, 'moneyness_width': 0.01},\n",
    "                {'direction': 'short', 'rel_strike': 0.85, 'dte': 365, 'moneyness_width': 0.01} \n",
    "            ],\n",
    "            'name': 'vertical_spread'\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "direction_index = {}\n",
    "str_direction_index = {}\n",
    "for indx, v in enumerate(order_settings['specifics']):\n",
    "    if v['direction'] == 'long':\n",
    "        str_direction_index[indx] = 'L'\n",
    "        direction_index[indx] = 1\n",
    "    elif v['direction'] == 'short':\n",
    "        str_direction_index[indx] = 'S'\n",
    "        direction_index[indx] = -1\n",
    "\n",
    "\n",
    "load_chain(date, 'TSLA')\n",
    "order_candidates = produce_order_candidates(order_settings, tick, date, right)\n",
    "\n",
    "if any([x2 is None for x in order_candidates.values() for x2 in x]):\n",
    "    return {\n",
    "        'result': \"MONEYNESS_TOO_TIGHT\",\n",
    "    } \n",
    "\n",
    "\n",
    "populate_cache(order_candidates, date=date)\n",
    "\n",
    "\n",
    "for direction in order_candidates:\n",
    "    for i,data in enumerate(order_candidates[direction]):\n",
    "        data['liquidity_check'] = data.option_id.apply(lambda x: liquidity_check(x, date))\n",
    "        data = data[data.liquidity_check == True]\n",
    "        data['available_close_check'] = data.option_id.apply(lambda x: available_close_check(x, date))\n",
    "        order_candidates[direction][i] = data[data.available_close_check == True] \n",
    "\n",
    "\n",
    "\n",
    "## Filter Unique Combinations per leg.\n",
    "unique_ids = {'long': [], 'short': []}\n",
    "for direction in order_candidates:\n",
    "    for i,data in enumerate(order_candidates[direction]):\n",
    "        unique_ids[direction].append(data[(data.liquidity_check == True) & (data.available_close_check == True)].option_id.unique().tolist())\n",
    "\n",
    "## Produce Tradeable Combinations\n",
    "tradeable_ids = list(product(*unique_ids['long'], *unique_ids['short']))\n",
    "tradeable_ids, unique_ids \n",
    "\n",
    "## Keep only unique combinations. Not repeating a contract.\n",
    "filtered = [t for t in tradeable_ids if len(set(t)) == len(t)]\n",
    "\n",
    "## Get the price of the structure\n",
    "## Using List Comprehension to sum the prices of the structure per index\n",
    "results = [\n",
    "    (*items, sum([direction_index[i] * spot_cache[f'{item}_{date}'] for i, item in enumerate(items)])) for items in filtered\n",
    "]\n",
    "\n",
    "## Convert to DataFrame, and sort by the price of the structure.\n",
    "return_dataframe = pd.DataFrame(results)\n",
    "cols = return_dataframe.columns.tolist()\n",
    "cols[-1] = 'close'\n",
    "return_dataframe.columns= cols\n",
    "return_dataframe = return_dataframe[(return_dataframe.close<= max_close) & (return_dataframe.close> 0)].sort_values('close', ascending = False).head(1)\n",
    "\n",
    "## Rename the columns to the direction names\n",
    "return_dataframe.columns = list(str_direction_index.values()) + ['close']\n",
    "return_order = return_dataframe[list(str_direction_index.values())].to_dict(orient = 'list')\n",
    "return_order\n",
    "\n",
    "## Create the trade_id with the direction and the id of the contract.\n",
    "id = ''\n",
    "for k, v in return_order.items():\n",
    "    id += f\"&{k}:{v[0]}\"\n",
    "\n",
    "return_order['trade_id'] = id\n",
    "return_order['close'] = return_dataframe.close.values[0]\n",
    "\n",
    "return_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        dict\n",
      "\u001b[0;31mString form:\u001b[0m {}\n",
      "\u001b[0;31mLength:\u001b[0m      0\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "dict() -> new empty dictionary\n",
      "dict(mapping) -> new dictionary initialized from a mapping object's\n",
      "    (key, value) pairs\n",
      "dict(iterable) -> new dictionary initialized as if via:\n",
      "    d = {}\n",
      "    for k, v in iterable:\n",
      "        d[k] = v\n",
      "dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      "    in the keyword argument list.  For example:  dict(one=1, two=2)"
     ]
    }
   ],
   "source": [
    "from trade.helpers.types import PositionData\n",
    "def prineter(x,y) -> PositionData:\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long': [3]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "class PositionData( TypedDict): \n",
    "    long: list[str]\n",
    "    short: list[str]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if (key == 'long' or key == 'short') and not isinstance(value, list):\n",
    "            raise ValueError(f'{key} must be a list')\n",
    "        \n",
    "        if key == 'long':\n",
    "            self.long = value\n",
    "        elif key == 'short':\n",
    "            self.short = value\n",
    "        else:\n",
    "            raise ValueError(f'Key {key} not recognized')\n",
    "        super().__setitem__(key, value)\n",
    "\n",
    "rr = PositionData()\n",
    "rr['long']  = [3]\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class Person(TypedDict):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "# Static type checking\n",
    "person: Person = {\"name\": \"John\", \"age\": 30}  # OK\n",
    "person = {\"name\": \"John\"}  # Error (age is missing)\n",
    "\n",
    "# Runtime behavior\n",
    "print(person['name'])  # No runtime type enforcement, behaves like a regular dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person: Person = {\"name\": \"John\", \"age\": 30}\n",
    "person = {\"name\": \"John\"} \n",
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>S</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [L, S, close]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task: https://api.github.com\n",
      "Starting task: https://api.spacexdata.com/v4/launches/latest\n",
      "Starting task: https://jsonplaceholder.typicode.com/todos/1\n",
      "Completed task: https://api.github.com\n",
      "Completed task: https://api.spacexdata.com/v4/launches/latest\n",
      "Completed task: https://jsonplaceholder.typicode.com/todos/1\n",
      "{'current_user_url': 'https://api.github.com/user', 'current_user_authorizations_html_url': 'https://github.com/settings/connections/applications{/client_id}', 'authorizations_url': 'https://api.github.com/authorizations', 'code_search_url': 'https://api.github.com/search/code?q={query}{&page,per_page,sort,order}', 'commit_search_url': 'https://api.github.com/search/commits?q={query}{&page,per_page,sort,order}', 'emails_url': 'https://api.github.com/user/emails', 'emojis_url': 'https://api.github.com/emojis', 'events_url': 'https://api.github.com/events', 'feeds_url': 'https://api.github.com/feeds', 'followers_url': 'https://api.github.com/user/followers', 'following_url': 'https://api.github.com/user/following{/target}', 'gists_url': 'https://api.github.com/gists{/gist_id}', 'hub_url': 'https://api.github.com/hub', 'issue_search_url': 'https://api.github.com/search/issues?q={query}{&page,per_page,sort,order}', 'issues_url': 'https://api.github.com/issues', 'keys_url': 'https://api.github.com/user/keys', 'label_search_url': 'https://api.github.com/search/labels?q={query}&repository_id={repository_id}{&page,per_page}', 'notifications_url': 'https://api.github.com/notifications', 'organization_url': 'https://api.github.com/orgs/{org}', 'organization_repositories_url': 'https://api.github.com/orgs/{org}/repos{?type,page,per_page,sort}', 'organization_teams_url': 'https://api.github.com/orgs/{org}/teams', 'public_gists_url': 'https://api.github.com/gists/public', 'rate_limit_url': 'https://api.github.com/rate_limit', 'repository_url': 'https://api.github.com/repos/{owner}/{repo}', 'repository_search_url': 'https://api.github.com/search/repositories?q={query}{&page,per_page,sort,order}', 'current_user_repositories_url': 'https://api.github.com/user/repos{?type,page,per_page,sort}', 'starred_url': 'https://api.github.com/user/starred{/owner}{/repo}', 'starred_gists_url': 'https://api.github.com/gists/starred', 'topic_search_url': 'https://api.github.com/search/topics?q={query}{&page,per_page}', 'user_url': 'https://api.github.com/users/{user}', 'user_organizations_url': 'https://api.github.com/user/orgs', 'user_repositories_url': 'https://api.github.com/users/{user}/repos{?type,page,per_page,sort}', 'user_search_url': 'https://api.github.com/search/users?q={query}{&page,per_page,sort,order}'}\n",
      "{'fairings': None, 'links': {'patch': {'small': 'https://images2.imgbox.com/eb/d8/D1Yywp0w_o.png', 'large': 'https://images2.imgbox.com/33/2e/k6VE4iYl_o.png'}, 'reddit': {'campaign': None, 'launch': 'https://www.reddit.com/r/spacex/comments/xvm76j/rspacex_crew5_launchcoast_docking_discussion_and/', 'media': None, 'recovery': None}, 'flickr': {'small': [], 'original': []}, 'presskit': None, 'webcast': 'https://youtu.be/5EwW8ZkArL4', 'youtube_id': '5EwW8ZkArL4', 'article': None, 'wikipedia': 'https://en.wikipedia.org/wiki/SpaceX_Crew-5'}, 'static_fire_date_utc': None, 'static_fire_date_unix': None, 'net': False, 'window': None, 'rocket': '5e9d0d95eda69973a809d1ec', 'success': True, 'failures': [], 'details': None, 'crew': ['62dd7196202306255024d13c', '62dd71c9202306255024d13d', '62dd7210202306255024d13e', '62dd7253202306255024d13f'], 'ships': [], 'capsules': ['617c05591bad2c661a6e2909'], 'payloads': ['62dd73ed202306255024d145'], 'launchpad': '5e9e4502f509094188566f88', 'flight_number': 187, 'name': 'Crew-5', 'date_utc': '2022-10-05T16:00:00.000Z', 'date_unix': 1664985600, 'date_local': '2022-10-05T12:00:00-04:00', 'date_precision': 'hour', 'upcoming': False, 'cores': [{'core': '633d9da635a71d1d9c66797b', 'flight': 1, 'gridfins': True, 'legs': True, 'reused': False, 'landing_attempt': True, 'landing_success': True, 'landing_type': 'ASDS', 'landpad': '5e9e3033383ecbb9e534e7cc'}], 'auto_update': True, 'tbd': False, 'launch_library_id': 'f33d5ece-e825-4cd8-809f-1d4c72a2e0d3', 'id': '62dd70d5202306255024d139'}\n",
      "{'userId': 1, 'id': 1, 'title': 'delectus aut autem', 'completed': False}\n",
      "Total time taken: 0.1384739875793457 seconds\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def fetch_data(session, url):\n",
    "    print(f\"Starting task: {url}\")\n",
    "    async with session.get(url) as response:\n",
    "        data = await response.json()\n",
    "        print(f\"Completed task: {url}\")\n",
    "        return data\n",
    "\n",
    "async def main():\n",
    "    urls = [\n",
    "        'https://api.github.com',\n",
    "        'https://api.spacexdata.com/v4/launches/latest',\n",
    "        'https://jsonplaceholder.typicode.com/todos/1'\n",
    "    ]\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_data(session, url) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for result in results:\n",
    "            print(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    asyncio.run(main())\n",
    "    print(f\"Total time taken: {time.time() - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to producing an order:\n",
    "\n",
    "- S1: RM recieves order settings from PM\n",
    "- S2: RM produces a dataframe of potential options based on settings (if two legs produce two dataframes)\n",
    "- S3: RM assesses if option passes all checks\n",
    "    - C1: Minimum Available close\n",
    "    - C2: Liquidity (Open Interest)\n",
    "    - C2.5: (for Spreads only) Ensure both legs are not the same\n",
    "    - Optional, to extend:\n",
    "    - C3: Bid-Ask Spread\n",
    "    \n",
    "- S4: Return picked order to portfolio manager, which places the order. \n",
    "- Example:\n",
    "    {'long': [optionid or {'strike', 'exp'}], 'short' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "eval(os.environ['ASYNC'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openbb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
